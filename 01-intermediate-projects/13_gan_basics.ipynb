{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative adversarial network (GAN) basics\n",
    "\n",
    "The `13_gan_basics` notebook introduces the foundational concepts of Generative Adversarial Networks (GANs), a powerful class of models used for generating realistic data. GANs consist of two networks, a Generator and a Discriminator, that are trained simultaneously in a competitive setting. \n",
    "\n",
    "This notebook covers preparing the dataset, defining the Generator model responsible for creating synthetic data, and defining the Discriminator model, which distinguishes between real and generated data.\n",
    "\n",
    "---\n",
    "\n",
    "**P.S.:** Since GAN models are so vast, this notebook is mostly an introduction to GAN itself. Training a GAN model takes place in a notebook right after this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Understanding GANs](#understanding-gans)\n",
    "2. [Setting up the environment](#setting-up-the-environment)\n",
    "3. [Preparing the dataset](#preparing-the-dataset)\n",
    "4. [Defining the Generator model](#defining-the-generator-model)\n",
    "5. [Defining the Discriminator model](#defining-the-discriminator-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding GANs\n",
    "\n",
    "Generative Adversarial Networks (GANs) are a class of machine learning models used to generate new data that resembles a given dataset. GANs consist of two neural networks that compete against each other: the **generator** and the **discriminator**. The generator attempts to create realistic data, while the discriminator tries to distinguish between real data (from the training set) and fake data (created by the generator)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Key concepts**\n",
    "Generative Adversarial Networks (GANs) are a class of deep learning models designed for generating realistic data. GANs consist of two neural networks, a **generator** and a **discriminator**, that compete against each other in a zero-sum game. The generator creates fake data, aiming to make it indistinguishable from real data, while the discriminator attempts to distinguish between real and fake data.\n",
    "\n",
    "Key components of GANs include:\n",
    "- **Generator**: Takes random noise as input and transforms it into synthetic data.\n",
    "- **Discriminator**: Evaluates whether the input data is real or generated.\n",
    "- **Adversarial Training**: The generator and discriminator are trained simultaneously, improving their performance iteratively.\n",
    "- **Loss Function**: Typically based on a minimax game, balancing the generator’s goal of \"fooling\" the discriminator and the discriminator’s goal of accurate classification.\n",
    "\n",
    "GANs are known for their ability to produce high-quality synthetic data, making them powerful tools for generative tasks.\n",
    "\n",
    "### **Applications**\n",
    "GANs are widely used in a variety of fields, including:\n",
    "- **Image generation**: Creating realistic images, such as faces or landscapes, from random inputs.\n",
    "- **Data augmentation**: Generating additional samples for training datasets, particularly for imbalanced datasets.\n",
    "- **Image-to-image translation**: Tasks like converting sketches to photos or black-and-white images to color.\n",
    "- **Video generation**: Generating frames for video content, animations, or simulations.\n",
    "- **Anomaly detection**: Training on normal data and using the discriminator to identify anomalies.\n",
    "\n",
    "### **Advantages**\n",
    "- **Versatile generative capabilities**: Capable of creating high-quality data across various domains.\n",
    "- **Unsupervised learning**: Requires no labeled data for training, only real examples.\n",
    "- **Realism**: Generates synthetic data that can closely resemble real-world data.\n",
    "- **Wide applicability**: Can be used in fields ranging from art and entertainment to scientific simulations.\n",
    "\n",
    "### **Challenges**\n",
    "- **Training instability**: GANs are notoriously difficult to train, with issues like mode collapse where the generator produces limited variations.\n",
    "- **Hyperparameter sensitivity**: Requires careful tuning of learning rates, model architectures, and optimization strategies.\n",
    "- **Evaluation difficulty**: Measuring the quality of generated data is non-trivial and often subjective.\n",
    "- **Resource intensity**: Training GANs can be computationally expensive, especially for high-resolution outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q1: How do you install the necessary libraries for working with GANs in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# !pip install numpy matplotlib scikit-learn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q2: How do you import the required modules for building and training GANs in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q3: How do you set up the environment to use a GPU, and how do you fallback to CPU if necessary in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q4: How do you set a random seed in PyTorch to ensure reproducibility when training a GAN?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q5: How do you load an image dataset such as MNIST or CIFAR-10 using `torchvision.datasets` in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data/train_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182040794/182040794 [07:06<00:00, 426516.86it/s] \n"
     ]
    }
   ],
   "source": [
    "dataset = torchvision.datasets.SVHN(root=\"./data\", split=\"train\", download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q6: How do you apply transformations such as resizing and normalization to the dataset to prepare it for training a GAN?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/train_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),  # Resize images to 64x64\n",
    "    transforms.ToTensor(),  # Convert images to tensor\n",
    "    transforms.Normalize([0.5], [0.5])  # Normalize pixel values between -1 and 1\n",
    "])\n",
    "\n",
    "transformed_dataset = torchvision.datasets.SVHN(root=\"./data\", split=\"train\", download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q7: How do you create DataLoaders in PyTorch to efficiently load batches of data for GAN training?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Generator model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q8: How do you define the architecture of the Generator model using PyTorch’s `nn.Module`?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),  # Latent vector size of 100\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),  # Output 3-channel image (RGB)\n",
    "            nn.Tanh()  # Output between -1 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q9: How do you create the latent vector (noise) that serves as input to the Generator model?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vector_size = 100\n",
    "noise = torch.randn(batch_size, latent_vector_size, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q10: How do you implement the forward pass for the Generator model in PyTorch to output fake data?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "\n",
    "fake_images = generator(noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Discriminator model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q11: How do you define the architecture of the Discriminator model using PyTorch’s `nn.Module`?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()  # Output between 0 and 1 (probability)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q12: How do you implement the forward pass for the Discriminator model to classify real and fake data?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "real_output = discriminator(torch.randn(batch_size, 3, 64, 64, device=device))  # Simulated real images\n",
    "fake_output = discriminator(fake_images.detach())  # Fake images from the Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q13: How do you initialize the weights for both the Generator and Discriminator models in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weights_init(m):  # Custom weights initialization function for both Generator and Discriminator\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "        \n",
    "generator.apply(weights_init)\n",
    "discriminator.apply(weights_init)  # Applying weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "if os.path.exists('data'):\n",
    "    shutil.rmtree('data')\n",
    "    print(\"Folder 'data' has been deleted.\")\n",
    "else:\n",
    "    print(\"Folder 'data' does not exist.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
