{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained CNNs in PyTorch\n",
    "\n",
    "Welcome to the `08_pretrained_cnns` notebook. This notebook is part of a portfolio designed to showcase essential concepts and techniques in PyTorch, with a focus on utilizing pretrained convolutional neural networks (CNNs). \n",
    "\n",
    "Pretrained models, which have been trained on large datasets like ImageNet, offer a powerful starting point for various image recognition tasks. This notebook explores topics such as loading and exploring pretrained models, preparing and preprocessing datasets, performing inference, and comparing different models. It also covers visualization techniques for model predictions and learned features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Understanding pretrained CNNs](#understanding-pretrained-cnns)\n",
    "2. [Setting up the environment](#setting-up-the-environment)\n",
    "3. [Loading and exploring pretrained models](#loading-and-exploring-pretrained-models)\n",
    "4. [Preparing and preprocessing the dataset](#preparing-and-preprocessing-the-dataset)\n",
    "5. [Performing inference with pretrained models](#performing-inference-with-pretrained-models)\n",
    "6. [Comparing different pretrained models](#comparing-different-pretrained-models)\n",
    "7. [Visualizing model predictions and features](#visualizing-model-predictions-and-features)\n",
    "8. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding pretrained CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q1: How do you install the necessary libraries for working with pretrained CNNs in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q2: How do you import the required modules for loading and using pretrained models in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q3: How do you set the device to GPU if available, otherwise default to CPU in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q4: How do you check the current version of PyTorch installed in your environment?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and exploring pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q5: How do you load a pretrained model like ResNet-50 from torchvision in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q6: How do you inspect the architecture of a loaded pretrained model in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q7: How do you modify the input layer of a pretrained model to match the input dimensions of your dataset?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q8: How do you extract and print out the names and shapes of all layers in a pretrained model using PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q9: How do you load a pretrained model with its weights frozen, so they are not updated during training?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q10: How do you replace the final fully connected layer of a pretrained model to fit the number of classes in your dataset?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing and preprocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q11: How do you load and preprocess an image dataset using `torchvision.datasets` and `transforms` to be compatible with a pretrained model?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q12: How do you apply normalization to an image dataset to match the input requirements of a pretrained model in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q13: How do you resize all images in your dataset to the required input size for a pretrained model in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q14: How do you create DataLoaders for training and validation datasets in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q15: How do you apply data augmentation techniques such as random horizontal flip and random crop to your training dataset in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing inference with pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q16: How do you perform inference on a single image using a pretrained model in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q17: How do you batch process multiple images for inference using a pretrained model in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q18: How do you decode the output of a pretrained model to obtain the predicted class labels?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q19: How do you calculate and display the top-5 predicted classes for an image using a pretrained model in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q20: How do you evaluate the accuracy of a pretrained model on an entire validation dataset in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing different pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q21: How do you load and compare the architectures of different pretrained models such as VGG16, ResNet50, and InceptionV3 in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q22: How do you measure and compare the inference time for different pretrained models on the same dataset in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q23: How do you evaluate and compare the accuracy of different pretrained models on the same validation dataset in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q24: How do you calculate and compare the number of parameters in different pretrained models using PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q25: How do you visualize and compare the feature maps generated by different pretrained models for the same input image in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing model predictions and features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q26: How do you visualize the predictions of a pretrained model for a batch of test images in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q27: How do you plot a confusion matrix for the predictions made by a pretrained model in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q28: How do you visualize the activation maps of specific layers in a pretrained model using techniques like Grad-CAM in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q29: How do you generate and visualize t-SNE plots for the features extracted by a pretrained model in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q30: How do you overlay the Grad-CAM activation map onto the original input image to interpret the model's focus areas?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
