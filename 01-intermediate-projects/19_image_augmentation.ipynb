{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image augmentation in PyTorch\n",
    "\n",
    "The `19_image_augmentation` notebook explores techniques for enhancing model performance through image augmentation, a method used to artificially expand training datasets by applying transformations to images. \n",
    "\n",
    "The notebook covers loading and visualizing datasets, applying basic and combined transformations, and building a comprehensive data augmentation pipeline. It also discusses augmenting the dataset, training a model with augmented data, evaluating the impact of augmentation, and experimenting with different augmentation strategies to find the most effective ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Understanding image augmentation](#understanding-image-augmentation)\n",
    "2. [Setting up the environment](#setting-up-the-environment)\n",
    "3. [Loading and visualizing the dataset](#loading-and-visualizing-the-dataset)\n",
    "4. [Applying basic image transformations](#applying-basic-image-transformations)\n",
    "5. [Combining multiple transformations](#combining-multiple-transformations)\n",
    "6. [Building a Data Augmentation pipeline](#building-a-data-augmentation-pipeline)\n",
    "7. [Augmenting the dataset](#augmenting-the-dataset)\n",
    "8. [Training a model with augmented data](#training-a-model-with-augmented-data)\n",
    "9. [Evaluating the impact of augmentation](#evaluating-the-impact-of-augmentation)\n",
    "10. [Experimenting with augmentation strategies](#experimenting-with-augmentation-strategies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding image augmentation\n",
    "\n",
    "Image augmentation is a crucial technique in computer vision for enhancing the generalization ability of machine learning models. It involves artificially increasing the size and diversity of a dataset by applying various transformations to the original images. These transformations are designed to create variations of the input images that the model might encounter during testing, improving its robustness and helping prevent overfitting.\n",
    "\n",
    "In the context of deep learning, image augmentation is particularly useful when working with limited data, allowing the model to train on more varied images without the need to manually collect additional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Why use image augmentation?**\n",
    "\n",
    "Image augmentation offers several key benefits:\n",
    "- **Improves generalization**: Augmented images expose the model to variations it may encounter in the real world, making the model less likely to overfit to the training data.\n",
    "- **Reduces overfitting**: By increasing the diversity of the training dataset, augmentation prevents the model from memorizing specific features of the dataset and encourages it to learn more general patterns.\n",
    "- **Works as a regularizer**: Similar to dropout or weight decay, augmentation serves as a form of regularization by creating slightly modified input images during training.\n",
    "\n",
    "### **Common image augmentation techniques**\n",
    "\n",
    "Several image augmentation techniques can be applied to transform images in different ways. These transformations modify the images while keeping their labels unchanged, ensuring that the task remains valid (e.g., a picture of a dog remains a picture of a dog after augmentation). Some of the most commonly used augmentations include:\n",
    "\n",
    "#### **Horizontal and vertical flipping**\n",
    "Flipping an image horizontally or vertically is one of the simplest augmentation techniques. This introduces variation by simulating a different perspective of the object in the image.\n",
    "\n",
    "- **Horizontal flipping**: Flips the image along the vertical axis, creating a mirror image.\n",
    "- **Vertical flipping**: Flips the image along the horizontal axis (less common in natural images but sometimes used in specific domains).\n",
    "\n",
    "#### **Rotation**\n",
    "Rotating images by a random angle introduces new orientations of the objects in the dataset. This is especially useful in applications where the orientation of objects is not fixed, such as aerial photography or medical imaging.\n",
    "\n",
    "#### **Scaling and zooming**\n",
    "Scaling refers to resizing the image, while zooming focuses on cropping a smaller area of the image and then resizing it to the original dimensions. Both techniques help the model generalize across different scales of objects in the image.\n",
    "\n",
    "#### **Cropping**\n",
    "Random cropping involves selecting a random portion of the image and resizing it to the original size. This introduces variation in how much of the object is visible in the image, forcing the model to focus on important features rather than memorizing specific positions.\n",
    "\n",
    "#### **Translation**\n",
    "Translation shifts the image horizontally or vertically by a random amount, introducing variation in the object’s position. This is particularly helpful in cases where the position of the object in the image can vary.\n",
    "\n",
    "#### **Shearing**\n",
    "Shearing skews the image along the x or y axis, altering its shape by stretching or compressing it. This transformation creates a different perspective of the object in the image.\n",
    "\n",
    "#### **Color jitter**\n",
    "Color jitter involves randomly changing the brightness, contrast, saturation, or hue of the image. This helps the model become more robust to lighting variations and color changes in the real world.\n",
    "\n",
    "#### **Gaussian noise**\n",
    "Adding Gaussian noise to the image can simulate sensor noise or poor-quality image capture. This helps the model learn to ignore minor noise and focus on the significant features in the image.\n",
    "\n",
    "#### **Blurring and sharpening**\n",
    "Blurring simulates out-of-focus images, while sharpening enhances edges and details. Both transformations help the model handle different image quality scenarios during inference.\n",
    "\n",
    "### **Combining augmentations**\n",
    "\n",
    "A powerful aspect of image augmentation is that multiple transformations can be applied sequentially or in combination to create more diverse variations of the images. For example, an image can be rotated, flipped, and then cropped, generating a new sample that is significantly different from the original. \n",
    "\n",
    "In practice, these augmentations are often applied randomly during each epoch of training, ensuring that the model sees a unique version of the image every time.\n",
    "\n",
    "### **Image augmentation in PyTorch**\n",
    "\n",
    "PyTorch provides robust support for image augmentation through the `torchvision.transforms` module, which offers a wide range of transformations that can be applied to images. The `transforms` module allows users to define a sequence of augmentations that are applied during training.\n",
    "\n",
    "Here’s how the typical augmentation pipeline works in PyTorch:\n",
    "1. **Composing augmentations**: Multiple transformations are applied sequentially using `transforms.Compose`. This allows you to define a pipeline where, for example, images are randomly rotated, flipped, and then normalized.\n",
    "2. **Random transformations**: Many of the transformations, such as `RandomHorizontalFlip`, `RandomRotation`, and `RandomResizedCrop`, apply random modifications to the images, ensuring that the model sees different variations during each epoch.\n",
    "\n",
    "### **Importance of normalization in image augmentation**\n",
    "\n",
    "After performing various augmentations, it's important to **normalize** the images so that the pixel values are within a specific range, typically between 0 and 1 or -1 and 1. Normalization helps the model train more effectively by keeping the pixel values on a consistent scale, reducing the risk of numerical instability in the network.\n",
    "\n",
    "Normalization is especially important when using pre-trained models, as many pre-trained models expect input images to be normalized in a specific way (e.g., to match the statistics of the ImageNet dataset).\n",
    "\n",
    "### **Benefits and trade-offs of image augmentation**\n",
    "\n",
    "While image augmentation provides many benefits, there are also some trade-offs to consider:\n",
    "- **Increased training time**: Since new variations of the data are generated on the fly, applying augmentations can slow down the training process. This can be mitigated using hardware acceleration or parallel processing.\n",
    "- **Choosing appropriate augmentations**: Not all augmentations are suitable for every dataset or task. For example, flipping might be irrelevant or even harmful in tasks where the orientation of the object is critical, such as in medical imaging.\n",
    "\n",
    "### **Applications of image augmentation**\n",
    "\n",
    "Image augmentation is widely used across various computer vision tasks, including:\n",
    "- **Image classification**: Augmentation techniques such as cropping, flipping, and rotation help models generalize better and avoid overfitting on training data.\n",
    "- **Object detection**: Augmentations like scaling and translation help the model learn to detect objects in different sizes and positions.\n",
    "- **Segmentation**: Augmentation can be used to improve performance in segmentation tasks, where precise boundaries of objects need to be detected despite variations in image quality or perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Maths**\n",
    "\n",
    "#### **Transformation matrix for geometric augmentations**\n",
    "\n",
    "Geometric augmentations, such as flipping, rotation, translation, and shearing, can be described using transformation matrices that operate on pixel coordinates in an image. A 2D image can be represented as a set of pixel coordinates $ (x, y) $, and applying a geometric transformation involves multiplying these coordinates by a transformation matrix.\n",
    "\n",
    "In the case of **rotation**, pixel coordinates are rotated by an angle $ \\theta $ around the origin using a 2D rotation matrix:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "x' \\\\\n",
    "y'\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\cos \\theta & -\\sin \\theta \\\\\n",
    "\\sin \\theta & \\cos \\theta\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Here, $ (x', y') $ are the new coordinates after rotation, and $ \\theta $ is the rotation angle.\n",
    "\n",
    "For **translation**, an image is shifted by adding a fixed offset $ t_x $ to the x-coordinates and $ t_y $ to the y-coordinates:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "x' \\\\\n",
    "y'\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "t_x \\\\\n",
    "t_y\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This shifts the image horizontally and vertically.\n",
    "\n",
    "In **scaling**, the x and y coordinates are multiplied by scale factors $ s_x $ and $ s_y $, respectively:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "x' \\\\\n",
    "y'\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "s_x & 0 \\\\\n",
    "0 & s_y\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Scaling adjusts the size of the image, with uniform scaling when $ s_x = s_y $.\n",
    "\n",
    "For **shearing**, the pixel coordinates are skewed along one axis. Horizontal shearing can be applied using the following matrix:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "x' \\\\\n",
    "y'\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 & \\text{shear\\_factor} \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x \\\\\n",
    "y\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Shearing alters the image by shifting the x-coordinate proportionally to the y-coordinate.\n",
    "\n",
    "#### **Random cropping and resizing**\n",
    "\n",
    "In random cropping, a subregion of the image, represented by a bounding box with coordinates $ (x_1, y_1, x_2, y_2) $, is selected. The selected region is then resized back to the original dimensions using interpolation techniques like bilinear or nearest-neighbor interpolation. Mathematically, resizing involves applying a scaling transformation to the cropped region.\n",
    "\n",
    "#### **Flipping**\n",
    "\n",
    "In **horizontal flipping**, the x-coordinates of all pixels are reversed:\n",
    "\n",
    "$$\n",
    "x' = \\text{image\\_width} - x\n",
    "$$\n",
    "\n",
    "This creates a mirror image along the vertical axis, while the y-coordinates remain unchanged.\n",
    "\n",
    "In **vertical flipping**, the y-coordinates are reversed:\n",
    "\n",
    "$$\n",
    "y' = \\text{image\\_height} - y\n",
    "$$\n",
    "\n",
    "The x-coordinates remain unchanged, creating a mirror image along the horizontal axis.\n",
    "\n",
    "#### **Color jittering**\n",
    "\n",
    "**Brightness adjustment** involves scaling the pixel intensity values $ I $ by a factor $ \\beta $:\n",
    "\n",
    "$$\n",
    "I' = I \\cdot \\beta\n",
    "$$\n",
    "\n",
    "Where $ \\beta $ is a random factor that changes the brightness of the image.\n",
    "\n",
    "For **contrast adjustment**, the pixel values are shifted based on their mean intensity $ \\mu $, and a contrast factor $ \\alpha $ is applied:\n",
    "\n",
    "$$\n",
    "I' = \\mu + (I - \\mu) \\cdot \\alpha\n",
    "$$\n",
    "\n",
    "In **saturation adjustment**, the saturation of the image in a different color space (such as HSV) is scaled by a factor $ \\gamma $:\n",
    "\n",
    "$$\n",
    "S' = S \\cdot \\gamma\n",
    "$$\n",
    "\n",
    "For **hue adjustment**, the hue values in the color space are shifted by $ \\delta $, and the transformation is expressed as:\n",
    "\n",
    "$$\n",
    "H' = (H + \\delta) \\mod 360\n",
    "$$\n",
    "\n",
    "This circularly shifts the hue values within the valid range [0, 360] degrees.\n",
    "\n",
    "#### **Adding noise**\n",
    "\n",
    "Gaussian noise is added to an image by sampling random noise values from a Gaussian distribution $ N(0, \\sigma^2) $, where $ \\sigma^2 $ controls the noise variance. The augmented image is generated as:\n",
    "\n",
    "$$\n",
    "I' = I + N\n",
    "$$\n",
    "\n",
    "Where $ N $ is the noise matrix, and each element is drawn from a Gaussian distribution.\n",
    "\n",
    "#### **Normalization**\n",
    "\n",
    "Normalization adjusts pixel values to a specific range, commonly between 0 and 1 or -1 and 1. The normalization formula is:\n",
    "\n",
    "$$\n",
    "I' = \\frac{I - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ I $ is the original pixel intensity,\n",
    "- $ \\mu $ is the mean intensity,\n",
    "- $ \\sigma $ is the standard deviation.\n",
    "\n",
    "This operation ensures consistent scaling across all input images, aiding the stability of neural network training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q1: How do you install the necessary libraries for applying image augmentation in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q2: How do you import the required modules for image loading, augmentation, and processing in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q3: How do you set up your environment to use a GPU, and how do you fallback to CPU if necessary in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and visualizing the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q4: How do you load an image dataset (e.g., CIFAR-10) using `torchvision.datasets` in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q5: How do you apply basic image transformations like `Resize` and `ToTensor` when loading a dataset in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q6: How do you visualize a few sample images from the dataset using `matplotlib` before applying any augmentations?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying basic image transformations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q7: How do you apply a random horizontal flip to images using `torchvision.transforms.RandomHorizontalFlip`?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q8: How do you apply a random rotation to images using `torchvision.transforms.RandomRotation`?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q9: How do you apply color jitter to images using `torchvision.transforms.ColorJitter`?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q10: How do you visualize the effect of each individual transformation on the images?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining multiple transformations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q11: How do you use `torchvision.transforms.Compose` to combine multiple transformations like flipping, rotation, and color jitter into a single pipeline?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q12: How do you visualize the effect of combined transformations on sample images from the dataset?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q13: How do you experiment with the order of transformations in the `Compose` pipeline and observe their combined effect on the dataset?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Data Augmentation pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q14: How do you create a more complex augmentation pipeline using `Compose`, adding transformations like `RandomCrop` and `RandomGrayscale`?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q15: How do you ensure that augmentations are only applied to the training set and not the validation or test sets?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q16: How do you modify the augmentation pipeline to apply different intensities of transformations such as stronger rotations or color jitter?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q17: How do you apply the augmentation pipeline to the training dataset using PyTorch’s `DataLoader`?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q18: How do you generate augmented variations of each image in the dataset to increase the size of the training data?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q19: How do you visualize a few augmented images alongside their original versions to verify the augmentation process?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model with augmented data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q20: How do you define a simple CNN model in PyTorch for training on the augmented dataset?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q21: How do you set up a training loop in PyTorch to train the CNN on the augmented dataset?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q22: How do you monitor and log the training loss and accuracy during the training process to ensure the model is learning correctly?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the impact of augmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q23: How do you evaluate the CNN model on a validation set to compare its performance with and without data augmentation?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q24: How do you measure the generalization performance of the model when trained with augmented data?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q25: How do you analyze overfitting in the model by comparing training accuracy with validation accuracy after augmentation?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with augmentation strategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q26: How do you experiment with different augmentation techniques, such as stronger rotations, zoom, or random erasing?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q27: How do you fine-tune augmentation parameters like rotation angles or color jitter intensity and observe their effect on the model’s performance?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q28: How do you test the performance impact of applying augmentation only during certain epochs of training?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q29: How do you experiment with applying different augmentations to different classes in the dataset to increase model robustness?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
