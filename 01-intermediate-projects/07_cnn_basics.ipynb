{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks (CNN) basics\n",
    "\n",
    "Welcome to the `07_cnn_basics` notebook. This notebook is designed to showcase concepts and techniques in PyTorch, with a focus on convolutional neural networks (CNNs). CNNs are widely used in computer vision tasks such as image classification.\n",
    "\n",
    "It explores topics such as loading and preprocessing image datasets, building and training a simple CNN model, evaluating its performance, and visualizing learned features. It also includes methods for improving the model using regularization techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Understanding CNNs](#understanding-cnns)\n",
    "2. [Setting up the environment](#setting-up-the-environment)\n",
    "3. [Loading and preprocessing the dataset](#loading-and-preprocessing-the-dataset)\n",
    "4. [Building a simple CNN model](#building-a-simple-cnn-model)\n",
    "5. [Training the CNN model](#training-the-cnn-model)\n",
    "6. [Evaluating the CNN model](#evaluating-the-cnn-model)\n",
    "7. [Visualizing intermediate outputs and filters](#visualizing-intermediate-outputs-and-filters)\n",
    "8. [Improving the model with regularization](#improving-the-model-with-regularization)\n",
    "9. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding CNNs\n",
    "\n",
    "Convolutional Neural Networks (CNNs) are a specialized type of artificial neural network designed for handling structured grid-like data, such as images. They are commonly used in computer vision tasks, including image classification, object detection, and segmentation. CNNs excel at automatically capturing spatial hierarchies in the data through the use of convolutional operations, which make them particularly well-suited for tasks involving visual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Key building blocks of CNNs**\n",
    "\n",
    "CNNs consist of a series of core components that work together to process input data and extract meaningful features:\n",
    "\n",
    "#### **Convolutional layer**  \n",
    "The convolutional layer is the core of any CNN architecture. It applies a set of filters (also called kernels) to the input data, such as an image. These filters move across the input, performing element-wise multiplication between the filter and local patches of the input data. The result is summed to produce a feature map, which captures the presence of certain patterns, such as edges or textures, in the image.\n",
    "\n",
    "Several key ideas make convolutional layers efficient:\n",
    "- **Local receptive field**: Neurons in CNNs are connected only to a small, localized region of the input data, preserving spatial relationships and reducing the number of parameters.\n",
    "- **Shared weights**: All neurons in a feature map share the same set of weights, allowing CNNs to detect patterns anywhere in the image.\n",
    "- **Strides**: The step size at which the filter moves across the input. Increasing the stride size reduces the spatial dimensions of the output feature maps.\n",
    "- **Padding**: Zero padding is often applied around the border of the input to control the output size.\n",
    "\n",
    "#### **Activation functions**  \n",
    "After the convolution operation, an activation function introduces non-linearity to the network. This is crucial for CNNs because the convolution operation itself is linear, and non-linearity allows the network to model complex patterns in the data.\n",
    "\n",
    "The most commonly used activation function in CNNs is the **ReLU** (Rectified Linear Unit). ReLU is favored because it is simple, effective, and helps mitigate the vanishing gradient problem, allowing networks to train faster.\n",
    "\n",
    "#### **Pooling layers**  \n",
    "Pooling layers downsample the spatial dimensions of the feature maps, reducing computational complexity and helping to prevent overfitting. Pooling is typically applied after the convolutional layer.\n",
    "\n",
    "The two most common types of pooling are:\n",
    "- **Max pooling**: Retains the maximum value from each patch of the feature map.\n",
    "- **Average pooling**: Computes the average value of each patch.\n",
    "\n",
    "Max pooling is more commonly used as it captures the most prominent features in a region of the image.\n",
    "\n",
    "#### **Fully connected layers**  \n",
    "Once the convolutional and pooling layers have extracted high-level features from the input data, fully connected layers perform the final classification or regression task. Each neuron in a fully connected layer is connected to every neuron in the previous layer. The last fully connected layer typically uses a **softmax** activation function to output probabilities across the different classes in a classification task.\n",
    "\n",
    "### **Architectural properties of CNNs**\n",
    "\n",
    "CNNs possess several architectural properties that make them highly effective for image-based tasks:\n",
    "\n",
    "- **Parameter sharing**: By sharing weights in convolutional layers, CNNs can detect features like edges regardless of their location in the image, significantly reducing the number of parameters compared to fully connected networks.\n",
    "- **Sparse connectivity**: Neurons in convolutional layers are connected to only a small subset of the input, which decreases the computational cost and improves efficiency.\n",
    "- **Translation invariance**: CNNs are naturally invariant to translations within the input data. This allows them to recognize objects even if their position in the image changes.\n",
    "\n",
    "### **Training a CNN**\n",
    "\n",
    "The process of training a CNN is similar to that of a traditional neural network, involving backpropagation and gradient descent. The difference lies in the handling of convolutional layers and filters.\n",
    "\n",
    "- **Forward pass**: The input (e.g., an image) is passed through the network, where each convolutional and pooling layer transforms it into a set of high-level feature maps.\n",
    "- **Loss calculation**: The final output is compared to the true labels using a loss function, such as cross-entropy for classification tasks.\n",
    "- **Backpropagation**: Gradients of the loss with respect to the weights in the convolutional and fully connected layers are computed using the chain rule, and the weights are updated to minimize the loss.\n",
    "\n",
    "### **Popular CNN architectures**\n",
    "\n",
    "Over the years, several CNN architectures have gained popularity due to their success in various challenges and applications:\n",
    "- **LeNet**: One of the earliest CNN architectures, designed for digit classification.\n",
    "- **AlexNet**: Pioneered deeper CNNs and won the ImageNet competition in 2012, sparking widespread interest in deep learning.\n",
    "- **VGG**: Introduced deeper networks with small filters (3x3) and uniform layer structures.\n",
    "- **ResNet**: Introduced residual connections, allowing for much deeper networks without the degradation of performance.\n",
    "\n",
    "### **Challenges in CNNs**\n",
    "\n",
    "Despite their success, CNNs have some limitations:\n",
    "- **Data requirements**: CNNs require large amounts of labeled data to avoid overfitting and to generalize well to new data.\n",
    "- **Computational cost**: Training deep CNNs on high-resolution images can be computationally expensive.\n",
    "- **Lack of rotation invariance**: CNNs are not inherently invariant to rotations or changes in scale, although this can be addressed through data augmentation techniques.\n",
    "\n",
    "### **Applications of CNNs**\n",
    "\n",
    "CNNs are widely used in many tasks beyond image classification, including:\n",
    "- **Object detection**: CNN-based architectures like YOLO and Faster R-CNN detect objects in images and videos.\n",
    "- **Image segmentation**: Architectures such as U-Net and fully convolutional networks (FCNs) are used for tasks like semantic segmentation.\n",
    "- **Generative tasks**: Generative adversarial networks (GANs) use CNNs to generate realistic images.\n",
    "- **Video analysis**: CNNs, often combined with recurrent neural networks (RNNs), are applied to video analysis for tasks like action recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Maths**\n",
    "\n",
    "#### **Structure of CNNs**\n",
    "\n",
    "##### **Convolutional layer**\n",
    "In CNNs, the convolutional layer performs the convolution operation, which is the mathematical basis of the feature extraction process. The operation applies filters to the input data, moving them across the image and computing a weighted sum of the input pixels in each region, followed by the addition of a bias term. This weighted sum is known as a **feature map**.\n",
    "\n",
    "For a filter with weights $W$, the convolution operation at a position $(i, j)$ of the input $X$ can be expressed as:\n",
    "$$\n",
    "S(i,j) = (X * W)(i,j) = \\sum_{m=0}^{k-1} \\sum_{n=0}^{k-1} W(m,n) \\cdot X(i+m,j+n) + b\n",
    "$$\n",
    "where:\n",
    "- $X(i+m,j+n)$ is the pixel value in the local region of the input.\n",
    "- $W(m,n)$ is the filter weight.\n",
    "- $b$ is the bias term.\n",
    "- $k$ is the size of the filter (e.g., 3x3).\n",
    "\n",
    "##### **Pooling layer**\n",
    "Pooling layers reduce the spatial dimensions of the feature maps by downsampling, which helps reduce computational complexity and avoid overfitting. The two main pooling operations are:\n",
    "\n",
    "- **Max pooling**: Takes the maximum value within a local region.\n",
    "- **Average pooling**: Takes the average value within a local region.\n",
    "\n",
    "Mathematically, for a given pooling window size $p \\times p$, max pooling at position $(i, j)$ is:\n",
    "$$\n",
    "P_{\\text{max}}(i,j) = \\max\\{S(i+m,j+n) : 0 \\leq m,n < p\\}\n",
    "$$\n",
    "where $S$ is the input feature map, and $m, n$ are the indices within the pooling window.\n",
    "\n",
    "##### **Fully connected layer**\n",
    "Fully connected layers in CNNs behave similarly to those in traditional neural networks. Each neuron computes a weighted sum of its inputs, plus a bias term, followed by an activation function:\n",
    "$$\n",
    "z_j = \\sum_{i=1}^{n} w_{ij} a_i + b_j\n",
    "$$\n",
    "where:\n",
    "- $a_i$ is the input to the neuron.\n",
    "- $w_{ij}$ is the weight connecting input $i$ to neuron $j$.\n",
    "- $b_j$ is the bias term.\n",
    "\n",
    "#### **Forward propagation in CNNs**\n",
    "\n",
    "Forward propagation in CNNs involves passing the input data through the layers, starting from the convolutional layers to the fully connected layers, to generate the output prediction.\n",
    "\n",
    "##### **Convolutional operation**\n",
    "In a convolutional layer, the convolution operation extracts features from the input using filters. As described above, the convolution operation can be written as:\n",
    "$$\n",
    "S(i,j) = \\sum_{m=0}^{k-1} \\sum_{n=0}^{k-1} W(m,n) \\cdot X(i+m,j+n) + b\n",
    "$$\n",
    "where the result $S(i,j)$ represents the activation of a neuron in the feature map.\n",
    "\n",
    "##### **Activation function**\n",
    "The output of each convolution is passed through a non-linear activation function, such as the **ReLU** (Rectified Linear Unit):\n",
    "$$\n",
    "f(z) = \\max(0, z)\n",
    "$$\n",
    "ReLU introduces non-linearity into the network, allowing it to learn more complex patterns.\n",
    "\n",
    "##### **Pooling operation**\n",
    "After applying the activation function, pooling layers downsample the feature maps by taking the maximum or average values from local regions, as previously defined.\n",
    "\n",
    "#### **Loss function in CNNs**\n",
    "\n",
    "The loss function measures the difference between the predicted output and the actual target. For classification tasks, **cross-entropy loss** is often used:\n",
    "$$\n",
    "L = -\\frac{1}{m} \\sum_{i=1}^{m} \\sum_{j=1}^{k} y_{ij} \\log(\\hat{y_{ij}})\n",
    "$$\n",
    "where:\n",
    "- $y_{ij}$ is the true label of class $j$ for sample $i$.\n",
    "- $\\hat{y_{ij}}$ is the predicted probability of class $j$ for sample $i$.\n",
    "- $m$ is the number of samples, and $k$ is the number of classes.\n",
    "\n",
    "#### **Backpropagation in CNNs**\n",
    "\n",
    "Backpropagation adjusts the weights of the filters and fully connected layers to minimize the loss function. The gradients of the loss with respect to the weights are calculated using the chain rule.\n",
    "\n",
    "##### **Gradient descent for filters**\n",
    "For a weight $W(m,n)$ in a convolutional layer, the weight update using gradient descent is:\n",
    "$$\n",
    "W(m,n) = W(m,n) - \\eta \\frac{\\partial L}{\\partial W(m,n)}\n",
    "$$\n",
    "where:\n",
    "- $\\eta$ is the learning rate.\n",
    "- $\\frac{\\partial L}{\\partial W(m,n)}$ is the gradient of the loss with respect to the filter weight.\n",
    "\n",
    "##### **Gradient calculation**\n",
    "The gradient of the loss with respect to a filter weight in a convolutional layer is computed as:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W(m,n)} = \\sum_{i=0}^{h-1} \\sum_{j=0}^{w-1} \\frac{\\partial L}{\\partial S(i,j)} \\cdot \\frac{\\partial S(i,j)}{\\partial W(m,n)}\n",
    "$$\n",
    "where:\n",
    "- $\\frac{\\partial L}{\\partial S(i,j)}$ is the gradient of the loss with respect to the feature map at position $(i,j)$.\n",
    "- $\\frac{\\partial S(i,j)}{\\partial W(m,n)}$ is the derivative of the convolutional operation.\n",
    "\n",
    "#### **Training a CNN**\n",
    "\n",
    "Training a CNN involves the following steps:\n",
    "1. **Initialize weights**: The weights of the filters and fully connected layers are initialized randomly.\n",
    "2. **Forward propagation**: The input passes through the convolutional, pooling, and fully connected layers to generate predictions.\n",
    "3. **Compute loss**: The loss function calculates the difference between predicted and true labels.\n",
    "4. **Backpropagation**: The gradients of the loss with respect to the weights are computed.\n",
    "5. **Update weights**: The weights are adjusted using gradient descent.\n",
    "6. **Repeat**: This process is repeated for several epochs until the network converges to a minimum loss.\n",
    "\n",
    "#### **Regularization in CNNs**\n",
    "\n",
    "Regularization techniques are used to prevent overfitting in CNNs:\n",
    "\n",
    "- **L2 regularization** adds a penalty to the loss function proportional to the sum of the squares of the weights:\n",
    "  $$\n",
    "  L_{\\text{ridge}} = L + \\lambda \\sum_{j} W_j^2\n",
    "  $$\n",
    "  where $\\lambda$ is the regularization parameter.\n",
    "- **Dropout**: During training, dropout randomly sets a fraction of the neurons to zero in each layer, reducing the network’s reliance on any specific neuron and improving generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q1: How do you install the required libraries and dependencies to work with PyTorch and CNNs?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n",
    "# !pip install matplotlib numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q2: How do you set device configurations (CPU/GPU) in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q3: How do you load and check the versions of PyTorch and other relevant libraries installed in your environment?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1\n",
      "torchvision version: 0.19.1\n",
      "NumPy version: 1.26.4\n",
      "matplotlib version: 3.9.2\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"torchvision version: {torchvision.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"matplotlib version: {matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q4: How do you set the random seed in PyTorch and other libraries to ensure reproducibility?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q5: How do you load a dataset using `torchvision` in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:12<00:00, 13973356.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define a transform to normalize the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Download and load the datasets\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q6: How do you normalize an image dataset for input into a CNN in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))  # CIFAR-10 mean and std\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q7: How do you split a dataset into training, validation, and test sets using PyTorch?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "dataset_size = len(train_set)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_set, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q8: How do you apply data augmentation techniques to increase the diversity of your training data in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # Data Augmentation: Random horizontal flip\n",
    "    transforms.RandomCrop(32, padding=4),  # Data Augmentation: Random crop\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q9: How do you create a DataLoader in PyTorch for efficient data loading?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q10: How do you apply preprocessing techniques to an image dataset in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Training dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize to 64x64\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Testing dataset\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q11: How do you define a simple CNN architecture in PyTorch using `nn.Module`?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q12: How do you add convolutional layers to your model in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q13: How do you implement pooling layers in a CNN using PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q14: How do you add ReLU activation functions to your CNN model in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q15: How do you flatten the output of convolutional layers to feed into fully connected layers in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q16: How do you initialize weights for the layers of your CNN model in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q17: How do you define the cross-entropy loss function for a classification task in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q18: How do you select and implement an optimizer for training a CNN in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q19: How do you implement the training loop in PyTorch to update model weights during CNN training?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q20: How do you monitor and visualize the training progress, such as loss and accuracy, during training in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q21: How do you evaluate the performance of your trained CNN on a validation or test set in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q22: How do you calculate and visualize a confusion matrix for your CNN model's predictions in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q23: How do you detect overfitting during CNN model evaluation by analyzing training and validation losses?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q24: How do you visualize the classification results of a CNN model on test data in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q25: How do you compute precision, recall, and F1-score for your CNN model's predictions in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing intermediate outputs and filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q26: How do you extract and visualize the output of a specific layer in your CNN model during inference in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q27: How do you visualize the learned filters of a convolutional layer in a trained CNN model using PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q28: How do you visualize the feature maps produced by the convolutional layers of a CNN in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q29: How do you use matplotlib to plot and analyze the filters and feature maps of a CNN model in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q30: How do you visualize the output of the last convolutional layer before flattening in your CNN model using PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the model with regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q31: How do you implement dropout in a CNN model in PyTorch to reduce overfitting?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q32: How do you apply weight decay to your CNN model in PyTorch using an optimizer?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q33: How do you implement data augmentation to improve generalization of your CNN model in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q34: How do you adjust hyperparameters such as learning rate and batch size to optimize CNN performance in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q35: How do you implement early stopping in PyTorch to prevent overfitting during CNN training?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q36: How do you analyze the impact of regularization techniques like dropout and weight decay on the validation loss during CNN training in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
