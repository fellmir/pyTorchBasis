{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Understanding self-attention](#understanding-self-attention)\n",
    "2. [Setting up the environment](#setting-up-the-environment)\n",
    "3. [Defining the input data](#defining-the-input-data)\n",
    "4. [Implementing scaled dot-product attention](#implementing-scaled-dot-product-attention)\n",
    "5. [Building multi-head self-attention](#building-multi-head-self-attention)\n",
    "6. [Building the position-wise feed-forward network](#building-the-position-wise-feed-forward-network)\n",
    "7. [Applying self-attention to a transformer block](#applying-self-attention-to-a-transformer-block)\n",
    "8. [Training the self-attention mechanism](#training-the-self-attention-mechanism)\n",
    "9. [Evaluating the self-attention model](#evaluating-the-self-attention-model)\n",
    "10. [Visualizing attention weights](#visualizing-attention-weights)\n",
    "11. [Experimenting with hyperparameters](#experimenting-with-hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding self-attention\n",
    "\n",
    "Self-attention is a powerful mechanism that has become a foundational component in modern deep learning models, especially in natural language processing (NLP) and computer vision. Self-attention allows a model to dynamically focus on different parts of the input sequence when making predictions, capturing relationships between all elements in a sequence regardless of their position. This mechanism has been key to the success of models like the Transformer, which rely on self-attention to process sequences efficiently in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **What is attention?**\n",
    "\n",
    "In the context of deep learning, attention is a mechanism that allows a model to focus on the most relevant parts of the input when making a decision. For example, in machine translation, when translating a word in a sentence, attention helps the model to focus on the corresponding words in the source language that are most related to the target word. Self-attention extends this concept by applying attention to different parts of a single input sequence, rather than between two sequences.\n",
    "\n",
    "### **How self-attention works**\n",
    "\n",
    "In a self-attention mechanism, each element of a sequence (such as a word in a sentence or a pixel in an image) attends to every other element in the sequence. The idea is to compute the relationships, or dependencies, between each element and all others, allowing the model to capture both local and global context.\n",
    "\n",
    "For each element in the input sequence, self-attention calculates a **weighted combination** of the other elements, with the weights indicating how much attention each element should pay to others. This dynamic weighting enables the model to better understand the relationships between different parts of the sequence.\n",
    "\n",
    "The key steps in self-attention are:\n",
    "- **Query**: Each element in the sequence generates a query vector, which represents the information that element is seeking from the other elements.\n",
    "- **Key**: Each element also generates a key vector, which represents the information it has to offer to the others.\n",
    "- **Value**: Finally, each element generates a value vector, which contains the actual information that will be passed to other elements.\n",
    "\n",
    "The core idea is that the attention mechanism compares the query of one element to the keys of all elements (including itself) to determine the importance of each element. Based on this importance, a weighted sum of the value vectors is computed, and this becomes the new representation for that element.\n",
    "\n",
    "### **Advantages of self-attention**\n",
    "\n",
    "Self-attention offers several advantages over traditional sequence-processing methods like recurrent neural networks (RNNs) or convolutional neural networks (CNNs):\n",
    "- **Capturing long-range dependencies**: Unlike RNNs, which struggle to capture dependencies between distant elements in a sequence due to their sequential nature, self-attention allows every element to directly attend to every other element. This makes it easier to capture long-range dependencies.\n",
    "- **Parallelization**: Because self-attention processes all elements in parallel (rather than sequentially, as in RNNs), it significantly speeds up computation, especially for long sequences.\n",
    "- **Flexibility**: Self-attention is not tied to a fixed input size, which makes it adaptable to tasks with varying input lengths, such as machine translation or image analysis.\n",
    "\n",
    "### **Multi-head attention**\n",
    "\n",
    "In practice, models often use **multi-head attention**, which splits the attention process into multiple \"heads.\" Each head processes the input sequence independently, attending to different aspects of the input. The outputs of these heads are then combined to create a richer representation. This multi-head mechanism allows the model to learn different relationships between elements of the input sequence simultaneously, improving its ability to capture complex patterns.\n",
    "\n",
    "For instance, in NLP tasks, one attention head might focus on word syntax, while another might focus on semantic relationships. By combining these different perspectives, the model gains a more comprehensive understanding of the sequence.\n",
    "\n",
    "### **Self-attention in Transformers**\n",
    "\n",
    "Self-attention is the core component of the **Transformer** architecture, which has revolutionized NLP by replacing the need for recurrent structures. In Transformers, self-attention layers enable the model to attend to all words in a sentence simultaneously, allowing it to build rich, context-aware representations. This parallelized approach enables faster training and better performance on tasks like language modeling, translation, and text generation.\n",
    "\n",
    "A key innovation in Transformers is the use of **positional encoding** to preserve the order of elements in a sequence, since self-attention alone is agnostic to the position of elements. Positional encodings are added to the input embeddings to ensure the model understands the sequential nature of the data.\n",
    "\n",
    "### **Applications of self-attention**\n",
    "\n",
    "Self-attention has broad applications across many fields, including:\n",
    "- **Natural language processing (NLP)**: Self-attention is heavily used in tasks like machine translation, text summarization, question-answering, and sentiment analysis, largely due to its role in the Transformer model and its derivatives, such as BERT and GPT.\n",
    "- **Computer vision**: Self-attention has been applied to vision tasks like object detection and image segmentation, where understanding the relationships between different parts of an image is critical.\n",
    "- **Speech recognition**: Self-attention has been used to improve speech recognition systems by enabling models to focus on important segments of audio sequences.\n",
    "\n",
    "### **Challenges of self-attention**\n",
    "\n",
    "Despite its advantages, self-attention comes with a few challenges:\n",
    "- **Computation cost**: The main drawback of self-attention is that its computational cost grows quadratically with the input sequence length. This can make it expensive for long sequences, particularly in tasks like document processing or video understanding.\n",
    "- **Memory usage**: Self-attention also requires a large amount of memory, as the model needs to compute and store attention weights for every pair of elements in the sequence.\n",
    "\n",
    "To address these challenges, various optimizations and alternatives have been proposed, such as **sparse attention mechanisms** or models like **Longformer**, which reduce the number of attention computations needed for longer sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Maths**\n",
    "\n",
    "#### **Self-attention mechanism**\n",
    "\n",
    "The self-attention mechanism allows each element in a sequence to focus on other elements when building its representation. The core idea is to compute a weighted combination of the entire sequence for each element, where the weights are determined by the similarity between the element and all other elements.\n",
    "\n",
    "For each input sequence, we compute three different representations:\n",
    "- **Query (Q)**: Represents what each element is looking for in other elements.\n",
    "- **Key (K)**: Represents the content that each element can offer to the others.\n",
    "- **Value (V)**: Contains the actual information that flows through the network.\n",
    "\n",
    "Let $ X \\in \\mathbb{R}^{n \\times d} $ be the input matrix, where $ n $ is the number of elements in the sequence, and $ d $ is the dimensionality of the embeddings. The query, key, and value matrices $ Q, K, V $ are computed as linear transformations of the input:\n",
    "\n",
    "$$\n",
    "Q = XW_Q, \\quad K = XW_K, \\quad V = XW_V\n",
    "$$\n",
    "\n",
    "Where $ W_Q, W_K, W_V \\in \\mathbb{R}^{d \\times d_k} $ are learned weight matrices that project the input $ X $ into the query, key, and value spaces, respectively, with dimensionality $ d_k $.\n",
    "\n",
    "#### **Scaled dot-product attention**\n",
    "\n",
    "The core of the self-attention mechanism is to compute the attention scores, which represent how much each element should focus on other elements. These scores are computed by taking the dot product between the query and key vectors:\n",
    "\n",
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ QK^T $ computes the dot product between the queries and keys for all pairs of elements in the sequence.\n",
    "- The term $ \\sqrt{d_k} $ is a scaling factor that prevents the dot product values from growing too large as the dimensionality $ d_k $ increases. Without this scaling, large values could lead to small gradients, slowing down training.\n",
    "- The **softmax** function ensures that the attention weights are normalized, so they sum to 1, making them comparable probabilities.\n",
    "- The resulting matrix is then multiplied by the value matrix $ V $, resulting in a weighted combination of the values based on the attention scores.\n",
    "\n",
    "#### **Multi-head attention**\n",
    "\n",
    "In practice, self-attention is often performed in parallel across multiple attention heads, allowing the model to capture different types of relationships in the data. In **multi-head attention**, the input is split into multiple heads, each with its own set of query, key, and value weight matrices:\n",
    "\n",
    "$$\n",
    "\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h) W_O\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ \\text{head}_i = \\text{Attention}(QW_{Q_i}, KW_{K_i}, VW_{V_i}) $ is the self-attention operation for each head $ i $,\n",
    "- $ W_{Q_i}, W_{K_i}, W_{V_i} $ are the learned weight matrices for the $ i $-th attention head,\n",
    "- $ W_O \\in \\mathbb{R}^{h \\cdot d_k \\times d} $ is the learned weight matrix used to combine the outputs of all heads.\n",
    "\n",
    "Each attention head focuses on different parts of the input, and by concatenating the results, the model captures a richer representation of the sequence.\n",
    "\n",
    "#### **Positional encoding**\n",
    "\n",
    "Since self-attention operates on the entire sequence in parallel, it lacks information about the relative positions of elements in the sequence. To inject positional information, **positional encodings** are added to the input embeddings. These encodings allow the model to differentiate between the positions of elements, ensuring that the order of the sequence is preserved.\n",
    "\n",
    "The positional encoding vector $ PE $ for position $ i $ is defined as:\n",
    "\n",
    "$$\n",
    "PE_{i, 2j} = \\sin\\left(\\frac{i}{10000^{2j/d}}\\right), \\quad PE_{i, 2j+1} = \\cos\\left(\\frac{i}{10000^{2j/d}}\\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ i $ is the position of the element in the sequence,\n",
    "- $ j $ is the index of the dimension in the encoding.\n",
    "\n",
    "These sinusoidal functions allow the model to infer relative positions, as the encoding for each position is unique and encodes both absolute and relative distance between elements.\n",
    "\n",
    "#### **Self-attention complexity**\n",
    "\n",
    "The self-attention mechanism requires computing the dot product between every pair of elements in the sequence. This results in a computational complexity of $ O(n^2 d_k) $, where $ n $ is the sequence length and $ d_k $ is the dimensionality of the queries and keys. This quadratic complexity can be costly, particularly for long sequences, which has led to the development of more efficient variants like sparse attention or linearized attention.\n",
    "\n",
    "#### **Training objectives**\n",
    "\n",
    "In models like the Transformer, self-attention is typically used in conjunction with other layers, such as feedforward networks and normalization layers. The training objective depends on the specific task:\n",
    "- For sequence-to-sequence tasks like translation, the model is trained to minimize a loss function (such as cross-entropy) between the predicted output and the ground truth sequence.\n",
    "- For unsupervised tasks like language modeling, the model is trained to predict the next token in a sequence given the preceding tokens.\n",
    "\n",
    "Self-attention layers are typically stacked multiple times, allowing the model to build progressively more complex representations of the input sequence by attending to different combinations of elements at each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q1: How do you install the necessary libraries for building and training self-attention models in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q2: How do you import the required modules for building attention mechanisms and handling data in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q3: How do you set up the environment to utilize a GPU for training self-attention models in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the input data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q4: How do you define sequence data, such as tokenized text, to be used as input for the self-attention mechanism?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q5: How do you preprocess and batch the input data to feed into the self-attention model?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q6: How do you create a DataLoader in PyTorch to load batches of sequential data for training?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing scaled dot-product attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q7: How do you implement the function for scaled dot-product attention in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q8: How do you calculate the attention scores by computing the dot product of the query and key matrices?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q9: How do you apply softmax to normalize the attention scores in the scaled dot-product attention mechanism?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q10: How do you compute the final output of the attention mechanism by multiplying the attention scores with the value matrix?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building multi-head self-attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q11: How do you define the architecture for multi-head self-attention using `torch.nn.Module` in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q12: How do you split the input into multiple heads and perform scaled dot-product attention for each head?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q13: How do you concatenate the outputs of the multiple attention heads and apply a final linear transformation?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the position-wise feed-forward network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q14: How do you define the position-wise feed-forward network using `torch.nn.Linear` layers in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q15: How do you apply the feed-forward network to each position in the sequence independently?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q16: How do you add a non-linearity (e.g., ReLU) between the linear layers in the feed-forward network?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying self-attention to a transformer block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q17: How do you combine multi-head self-attention with layer normalization and residual connections in a transformer block?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q18: How do you implement the forward pass of the transformer block, including both self-attention and feed-forward layers?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q19: How do you stack multiple transformer blocks to create a deep self-attention model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the self-attention mechanism\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q20: How do you define the loss function (e.g., CrossEntropyLoss) for training a self-attention model in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q21: How do you set up the optimizer (e.g., Adam) to update the parameters of the self-attention model during training?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q22: How do you implement the training loop for the self-attention mechanism, including forward pass, loss calculation, and backpropagation?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q23: How do you track and log the training loss over epochs to monitor the performance of the self-attention model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the self-attention model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q24: How do you evaluate the self-attention model on validation or test data after training?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q25: How do you calculate the accuracy or other metrics (e.g., BLEU score, F1 score) to assess the modelâ€™s performance?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q26: How do you implement a function to perform inference using the trained self-attention model on new input sequences?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing attention weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q27: How do you extract attention weights from the model to analyze how the self-attention mechanism focuses on different parts of the input sequence?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q28: How do you visualize the attention weights as heatmaps to show which tokens or elements the model attends to during the forward pass?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q29: How do you interpret the attention heatmaps to understand how attention is distributed across layers and heads?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q30: How do you experiment with different numbers of attention heads and analyze their effect on model performance and training time?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q31: How do you adjust the hidden dimension size of the self-attention mechanism and observe its impact on accuracy and convergence?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q32: How do you experiment with varying the number of transformer blocks in the model and analyze how it affects the results?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q33: How do you tune learning rates and dropout rates to improve the generalization of the self-attention model?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q34: How do you analyze the effect of different activation functions (e.g., ReLU, GELU) in the feed-forward network on training stability?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
