{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-series forecasting in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Understanding time-series forecasting](#understanding-time-series-forecasting)\n",
    "2. [Setting up the environment](#setting-up-the-environment)\n",
    "3. [Loading and visualizing time-series data](#loading-and-visualizing-time-series-data)\n",
    "4. [Data preprocessing for time-series forecasting](#data-preprocessing-for-time-series-forecasting)\n",
    "5. [Building a simple fully connected network](#building-a-simple-fully-connected-network)\n",
    "6. [Training the time-series forecasting model](#training-the-time-series-forecasting-model)\n",
    "7. [Evaluating the forecasting model](#evaluating-the-forecasting-model)\n",
    "8. [Experimenting with different model architectures](#experimenting-with-different-model-architectures)\n",
    "9. [Making predictions on new data](#making-predictions-on-new-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding time-series forecasting\n",
    "\n",
    "Time-series forecasting is a crucial task in machine learning that involves predicting future values based on historical data. Time-series data is sequential, with observations made over regular intervals, such as daily stock prices, weather measurements, or sales data. The goal of time-series forecasting is to model this temporal structure and make accurate predictions about future values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Key challenges in time-series forecasting**\n",
    "\n",
    "Time-series forecasting is unique due to the sequential nature of the data, and this brings several challenges:\n",
    "- **Temporal dependence**: In time-series data, each data point is dependent on the previous points. This temporal dependency requires models that can capture and learn from these relationships over time.\n",
    "- **Seasonality and trends**: Many time-series datasets exhibit repeating patterns (seasonality) or long-term trends. A good forecasting model must account for both these factors to make accurate predictions.\n",
    "- **Noise and irregularities**: Real-world time-series data is often noisy, with irregular patterns that make forecasting more difficult. Models need to be robust enough to handle these fluctuations.\n",
    "\n",
    "### **Why use PyTorch for time-series forecasting?**\n",
    "\n",
    "PyTorch is a flexible and powerful framework that provides the tools necessary for building time-series forecasting models. Its dynamic computational graph and ease of use for implementing custom architectures make it an excellent choice for handling the complexity of time-series data.\n",
    "\n",
    "In particular, PyTorch provides several features that are beneficial for time-series forecasting:\n",
    "- **Recurrent neural networks (RNNs)**: These networks are designed to handle sequential data by maintaining a memory of previous inputs, making them suitable for modeling time-series data.\n",
    "- **Convolutional neural networks (CNNs)**: CNNs can be adapted for time-series tasks by applying convolution operations to the sequence, helping the model capture patterns such as trends or seasonality.\n",
    "- **Attention mechanisms**: These mechanisms allow the model to focus on the most relevant parts of the input sequence when making predictions, improving performance on tasks with long-range dependencies.\n",
    "\n",
    "### **Common approaches to time-series forecasting**\n",
    "\n",
    "There are several common approaches to time-series forecasting in PyTorch, each with its own strengths and weaknesses:\n",
    "\n",
    "#### **Autoregressive models**\n",
    "In autoregressive models, the output at a given time step is predicted based on the previous observations in the sequence. The model directly learns the dependencies between the past and future data points. This approach is useful for short-term forecasting but may struggle with long-range dependencies.\n",
    "\n",
    "#### **Recurrent neural networks (RNNs)**\n",
    "RNNs are a type of neural network that excels in processing sequential data by maintaining a hidden state that is updated at each time step. This hidden state allows the model to retain information from previous time steps, making it suitable for time-series forecasting tasks. However, RNNs can suffer from issues such as the vanishing gradient problem, which makes it difficult to learn long-range dependencies in very long sequences.\n",
    "\n",
    "#### **Convolutional neural networks (CNNs) for time series**\n",
    "CNNs can be adapted to time-series forecasting by treating the sequence as a 1D signal and applying convolutional filters over time. These filters allow the model to capture short-term dependencies, trends, and patterns, making CNNs a good option for time-series tasks that involve local patterns or periodicity. The primary benefit of CNNs is their ability to learn efficiently from local correlations in the data, while also being computationally efficient.\n",
    "\n",
    "#### **Transformers and attention mechanisms**\n",
    "The transformer architecture, originally designed for NLP tasks, has recently been adapted for time-series forecasting. Attention mechanisms, which are central to transformers, allow the model to weigh the importance of different time steps in the sequence, making them particularly effective at capturing long-range dependencies.\n",
    "\n",
    "Attention-based models focus on the most relevant parts of the input sequence at each time step, allowing the model to handle complex time-series data with long-term dependencies more effectively than traditional RNNs. The flexibility of attention mechanisms helps the model focus on important patterns, even when those patterns are far back in the sequence.\n",
    "\n",
    "### **Handling seasonality and trends**\n",
    "\n",
    "A key part of time-series forecasting is handling seasonal patterns and long-term trends in the data. Many real-world time-series datasets exhibit seasonality, where patterns repeat at regular intervals (e.g., daily, weekly, or yearly patterns). Detecting and modeling these trends is crucial for making accurate forecasts.\n",
    "\n",
    "- **Seasonality**: Time-series forecasting models often include features that capture seasonal effects, such as day of the week, time of year, or periodic events. These features allow the model to recognize repeating patterns and improve its predictions.\n",
    "- **Trend**: Long-term trends in the data represent gradual increases or decreases over time. Capturing these trends in the model helps to account for the overall direction of the time-series data.\n",
    "\n",
    "In PyTorch, seasonality and trends can be incorporated into models through the use of additional features or by designing architectures that can capture these patterns directly.\n",
    "\n",
    "### **Dealing with missing data and irregular intervals**\n",
    "\n",
    "Real-world time-series data is often messy, with missing values or irregular intervals between observations. Handling missing data effectively is crucial for building robust forecasting models.\n",
    "\n",
    "Some common strategies for dealing with missing data in time-series forecasting include:\n",
    "- **Imputation**: Filling in missing values with estimates based on surrounding data points. This can be done using simple techniques like forward-filling or more advanced methods like interpolation.\n",
    "- **Ignoring missing data**: In some cases, it may be feasible to simply ignore missing values if they are sparse or donâ€™t significantly affect the overall trend.\n",
    "- **Training models to handle gaps**: Some models can be designed to handle irregular intervals directly, by learning how to predict in the presence of gaps in the data.\n",
    "\n",
    "### **Forecasting horizons**\n",
    "\n",
    "Time-series forecasting models must also be able to handle different forecasting horizons, which refers to how far into the future the model is trying to predict. Some models may perform well for short-term forecasting but struggle with long-term predictions.\n",
    "\n",
    "- **Short-term forecasting**: Models are typically good at predicting a few steps ahead, where the temporal dependencies are strong and recent observations are more predictive.\n",
    "- **Long-term forecasting**: Predicting further into the future is more difficult, as the model must rely on learning long-range dependencies and identifying trends that extend beyond recent observations.\n",
    "\n",
    "In PyTorch, architectures like attention-based models and transformers are often used for long-term forecasting, as they can better capture and weigh information from distant time steps.\n",
    "\n",
    "### **Applications of time-series forecasting**\n",
    "\n",
    "Time-series forecasting is used in a wide range of applications, including:\n",
    "- **Financial markets**: Predicting stock prices, exchange rates, or interest rates based on historical market data.\n",
    "- **Weather forecasting**: Modeling weather patterns to predict temperature, rainfall, or other meteorological variables.\n",
    "- **Supply chain management**: Forecasting demand, inventory levels, and shipping times to optimize supply chain operations.\n",
    "- **Energy consumption**: Predicting future energy usage to inform resource management and grid stability.\n",
    "\n",
    "These are just a few examples of the many areas where time-series forecasting plays a critical role in decision-making processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Maths**\n",
    "\n",
    "#### **Fully connected network (FCN)**\n",
    "\n",
    "A fully connected network (FCN) is one of the simplest architectures used for time-series forecasting. In this setup, every neuron in one layer is connected to every neuron in the next layer. The input is typically the time-series data, and the output is the predicted future value. The relationship between the input $ x $ and output $ \\hat{y} $ can be represented as a linear transformation followed by a non-linear activation function.\n",
    "\n",
    "For a single layer in an FCN, the transformation can be written as:\n",
    "\n",
    "$$\n",
    "\\hat{y} = W \\cdot x + b\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ W $ is the weight matrix that connects the input $ x $ to the output $ \\hat{y} $,\n",
    "- $ b $ is the bias vector.\n",
    "\n",
    "This linear transformation is often followed by an activation function, such as ReLU or sigmoid, to introduce non-linearity, which allows the network to model more complex patterns in the data.\n",
    "\n",
    "The FCN can be extended by adding more layers, each applying similar transformations. In time-series forecasting, the input to the network might be a window of previous observations, and the output is the predicted value for the next time step.\n",
    "\n",
    "#### **Autoregressive models**\n",
    "\n",
    "Autoregressive models predict future values based on a linear combination of past observations. In an autoregressive (AR) model of order $ p $, the value at time step $ t $ is predicted based on the previous $ p $ time steps:\n",
    "\n",
    "$$\n",
    "x_t = \\phi_1 x_{t-1} + \\phi_2 x_{t-2} + \\dots + \\phi_p x_{t-p} + \\epsilon_t\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ x_t $ is the predicted value at time step $ t $,\n",
    "- $ \\phi_1, \\dots, \\phi_p $ are the coefficients of the model,\n",
    "- $ \\epsilon_t $ is the error term at time step $ t $.\n",
    "\n",
    "The model learns the coefficients $ \\phi_1, \\dots, \\phi_p $ to minimize the error $ \\epsilon_t $, which represents the difference between the predicted and actual values.\n",
    "\n",
    "#### **Recurrent neural networks (RNNs)**\n",
    "\n",
    "Recurrent neural networks (RNNs) are commonly used for time-series forecasting due to their ability to handle sequential data. In an RNN, the output at time step $ t $ depends not only on the input at time step $ t $ but also on the hidden state from the previous time step $ t-1 $.\n",
    "\n",
    "The hidden state $ h_t $ at time step $ t $ is updated based on the input $ x_t $ and the hidden state from the previous time step $ h_{t-1} $:\n",
    "\n",
    "$$\n",
    "h_t = f(W_h h_{t-1} + W_x x_t + b_h)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ W_h $ and $ W_x $ are weight matrices,\n",
    "- $ b_h $ is the bias,\n",
    "- $ f $ is an activation function (such as tanh or ReLU).\n",
    "\n",
    "The output at time step $ t $ is computed based on the hidden state:\n",
    "\n",
    "$$\n",
    "\\hat{y}_t = g(W_o h_t + b_o)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ W_o $ is the weight matrix for the output,\n",
    "- $ g $ is an output activation function.\n",
    "\n",
    "RNNs are capable of capturing dependencies across time steps, making them well-suited for modeling time-series data.\n",
    "\n",
    "#### **Convolutional neural networks (CNNs) for time series**\n",
    "\n",
    "Convolutional neural networks (CNNs) can also be applied to time-series forecasting by treating the sequence as a 1D signal. The convolution operation involves applying filters over the input sequence to capture local patterns. The output at time step $ t $ in a 1D convolutional layer can be expressed as:\n",
    "\n",
    "$$\n",
    "y_t = \\sum_{i=0}^{k-1} w_i x_{t-i}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ y_t $ is the output at time step $ t $,\n",
    "- $ w_i $ are the weights of the filter (or kernel),\n",
    "- $ k $ is the size of the filter,\n",
    "- $ x_{t-i} $ are the input values at time steps $ t-i $.\n",
    "\n",
    "This convolutional operation captures local dependencies in the data, making CNNs useful for detecting short-term trends and patterns in time-series data.\n",
    "\n",
    "#### **Attention mechanisms**\n",
    "\n",
    "Attention mechanisms are used to allow the model to focus on the most relevant parts of the input sequence when making predictions. The attention score $ \\alpha_{t,i} $ between the current time step $ t $ and a previous time step $ i $ is computed as:\n",
    "\n",
    "$$\n",
    "\\alpha_{t,i} = \\frac{\\exp(e_{t,i})}{\\sum_{j} \\exp(e_{t,j})}\n",
    "$$\n",
    "\n",
    "Where $ e_{t,i} $ is the alignment score between the hidden states at time steps $ t $ and $ i $. The attention weights $ \\alpha_{t,i} $ are used to compute a context vector $ c_t $, which is a weighted sum of the input sequence:\n",
    "\n",
    "$$\n",
    "c_t = \\sum_{i} \\alpha_{t,i} h_i\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ h_i $ is the hidden state at time step $ i $,\n",
    "- $ \\alpha_{t,i} $ are the attention weights.\n",
    "\n",
    "This context vector $ c_t $ is then used to predict the output at time step $ t $, allowing the model to focus on the most important time steps when making predictions.\n",
    "\n",
    "#### **Handling seasonality and trends**\n",
    "\n",
    "Time-series data often exhibits patterns of seasonality and trends. Seasonality refers to repeating patterns over a fixed period (e.g., daily, weekly, or yearly), while trends represent long-term movements in the data. A common approach is to model the time series as a combination of these components:\n",
    "\n",
    "$$\n",
    "x_t = T_t + S_t + R_t\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ T_t $ is the trend component,\n",
    "- $ S_t $ is the seasonal component,\n",
    "- $ R_t $ is the residual (noise) component.\n",
    "\n",
    "By modeling these components, the forecasting model can capture both long-term trends and repeating seasonal patterns, improving the accuracy of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q1: How do you install the necessary libraries such as PyTorch, `pandas`, and `matplotlib` for time-series forecasting?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q2: How do you import the required PyTorch modules for model building and training in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q3: How do you configure the environment to use a GPU for faster model training in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and visualizing time-series data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q4: How do you load time-series data from a CSV file using `pandas` in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q5: How do you plot the time-series data to visualize patterns, trends, and seasonality using `matplotlib`?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q6: How do you split the time-series dataset into training and test sets for model evaluation?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing for time-series forecasting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q7: How do you normalize or standardize time-series data to improve model performance?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q8: How do you create sliding windows of input sequences and corresponding target values from the time-series data?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q9: How do you reshape time-series data into the correct format for feeding into a neural network?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q10: How do you create a `DataLoader` in PyTorch to batch the preprocessed time-series data for training?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple fully connected network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q11: How do you define a simple fully connected network (FCN) in PyTorch for time-series forecasting?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q12: How do you implement the forward pass of the FCN, where the input is a sequence of time-series data and the output is the predicted value?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q13: How do you add dropout and ReLU activation functions to the fully connected network to improve generalization?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the time-series forecasting model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q14: How do you define the loss function for training the time-series forecasting model?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q15: How do you set up the optimizer to update the parameters of the FCN during training?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q16: How do you implement the training loop, including the forward pass, loss calculation, and backpropagation for the time-series forecasting model?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q17: How do you log and track the training loss over multiple epochs to monitor model performance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the forecasting model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q18: How do you evaluate the forecasting model on the test set by calculating metrics such as Mean Absolute Error (MAE) or Root Mean Squared Error (RMSE)?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q19: How do you visualize the predicted vs. actual values for the test set to assess the accuracy of the model?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q20: How do you compare the performance of the forecasting model to a baseline method?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with different model architectures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q21: How do you experiment with different network architectures, such as adding more hidden layers or changing the number of neurons in the FCN?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q22: How do you implement and test a simple recurrent neural network (RNN) architecture for time-series forecasting?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q23: How do you experiment with different input window sizes to see how they affect the model's performance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on new data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q24: How do you use the trained model to make predictions on new time-series data?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q25: How do you implement multi-step forecasting, where the model predicts multiple future time steps based on historical data?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q26: How do you visualize the model's future predictions alongside the actual future values to evaluate its forecasting accuracy?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
