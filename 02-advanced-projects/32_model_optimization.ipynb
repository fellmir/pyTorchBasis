{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model optimization in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Understanding model optimization](#understanding-model-optimization)\n",
    "2. [Setting up the environment](#setting-up-the-environment)\n",
    "3. [Profile memory usage and performance](#profile-memory-usage-and-performance)\n",
    "4. [Using mixed precision training](#using-mixed-precision-training)\n",
    "5. [Pruning neural network models](#pruning-neural-network-models)\n",
    "6. [Applying layer fusion for optimization](#applying-layer-fusion-for-optimization)\n",
    "7. [Optimizing model checkpoints](#optimizing-model-checkpoints)\n",
    "8. [Using model parallelism](#using-model-parallelism)\n",
    "9. [Evaluating the optimized model](#evaluating-the-optimized-model)\n",
    "10. [Experimenting with different optimization techniques](#experimenting-with-different-optimization-techniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding model optimization\n",
    "\n",
    "Model optimization is a critical step in deep learning to ensure that a model performs efficiently, both in terms of accuracy and computational resources. In PyTorch, optimizing models involves various strategies to enhance performance, reduce resource consumption, and improve generalization on unseen data. These strategies are particularly important when deploying models in production environments, where the balance between speed and accuracy is key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Why optimize models?**\n",
    "\n",
    "Optimization is essential for several reasons:\n",
    "- **Improved performance**: A well-optimized model can deliver better accuracy or lower error rates on the given task.\n",
    "- **Efficiency**: Optimized models consume fewer computational resources, making them faster to train and deploy. This is especially important when deploying models on resource-constrained devices such as mobile phones or embedded systems.\n",
    "- **Scalability**: Optimized models can handle larger datasets and more complex tasks efficiently, making them easier to scale in production environments.\n",
    "- **Lower energy consumption**: Optimization reduces the energy required to train and deploy models, which is important for sustainability, particularly in large-scale machine learning systems.\n",
    "\n",
    "### **Key techniques for model optimization in PyTorch**\n",
    "\n",
    "#### **Hyperparameter tuning**\n",
    "\n",
    "One of the most fundamental aspects of model optimization is tuning the hyperparameters that control the learning process. These include:\n",
    "- **Learning rate**: Adjusting the learning rate can significantly impact how quickly the model converges during training. A learning rate that is too high can cause the model to overshoot the optimal solution, while one that is too low can lead to slow convergence.\n",
    "- **Batch size**: The size of the batch used during training affects the model’s speed and generalization ability. Larger batch sizes allow for faster training but may lead to poorer generalization, while smaller batches can improve generalization but slow down training.\n",
    "- **Weight decay**: Regularization techniques like weight decay add a penalty to large weight values, helping prevent overfitting by encouraging the model to learn simpler, more generalizable patterns.\n",
    "\n",
    "Finding the right combination of these hyperparameters can greatly improve the model's performance and efficiency. This process often involves a trial-and-error approach, or more systematic techniques like grid search, random search, or even automated methods like Bayesian optimization.\n",
    "\n",
    "#### **Early stopping**\n",
    "\n",
    "**Early stopping** is a regularization technique used to avoid overfitting by monitoring the model’s performance on a validation set during training. When the validation performance no longer improves, training is halted before the model overfits the training data. This method is particularly useful when dealing with limited datasets, where overfitting is more likely.\n",
    "\n",
    "In PyTorch, early stopping can be easily implemented by tracking the validation loss during training and stopping once the loss stops decreasing.\n",
    "\n",
    "#### **Gradient clipping**\n",
    "\n",
    "In deep learning models, especially recurrent neural networks (RNNs) and other deep architectures, the gradients can sometimes become too large during training, leading to unstable updates and slow convergence. **Gradient clipping** is a technique used to prevent the gradients from growing too large by capping them at a predefined threshold. This ensures that the training process remains stable and converges efficiently.\n",
    "\n",
    "#### **Optimizer selection**\n",
    "\n",
    "Choosing the right optimizer is crucial for model optimization. PyTorch offers several optimizers, each with its strengths and weaknesses:\n",
    "- **SGD (Stochastic Gradient Descent)**: A simple and commonly used optimizer that updates model parameters by following the gradient of the loss function. While effective, it may be slow to converge, especially when the loss function has many local minima or saddle points.\n",
    "- **Adam**: One of the most popular optimizers due to its adaptability and faster convergence. Adam combines the benefits of both SGD with momentum and RMSProp, making it effective for a wide range of tasks.\n",
    "- **RMSProp**: An adaptive learning rate method that adjusts the learning rate based on the magnitude of recent gradients. RMSProp is particularly useful in cases where gradients vary in magnitude across different dimensions of the parameter space.\n",
    "\n",
    "Each optimizer can be further tuned using its own set of hyperparameters, such as learning rates, momentum, and beta values, to improve the model's performance.\n",
    "\n",
    "#### **Data augmentation**\n",
    "\n",
    "In tasks like image classification or object detection, **data augmentation** is a powerful technique to optimize model performance. By artificially increasing the diversity of the training data, the model learns to generalize better to unseen data. Common data augmentation techniques include:\n",
    "- **Random cropping**: Extracting random patches of images to introduce variability in the input.\n",
    "- **Flipping and rotation**: Flipping images horizontally or vertically, or rotating them by random degrees, helps the model become invariant to changes in orientation.\n",
    "- **Color jittering**: Modifying the brightness, contrast, and saturation of images to help the model become more robust to lighting changes.\n",
    "\n",
    "In PyTorch, data augmentation is typically applied using the `torchvision.transforms` module, which provides a wide range of preprocessing functions to enhance the dataset during training.\n",
    "\n",
    "#### **Batch normalization**\n",
    "\n",
    "**Batch normalization** is a technique used to standardize the inputs to each layer of a neural network, ensuring that they have a mean of 0 and a variance of 1. This has two main benefits:\n",
    "- It stabilizes the training process by reducing the problem of internal covariate shift, where the distribution of inputs to each layer changes as the model parameters update.\n",
    "- It allows for the use of higher learning rates, which can speed up convergence.\n",
    "\n",
    "Batch normalization is commonly used in convolutional neural networks (CNNs) and deep neural networks to improve both training speed and model accuracy. In PyTorch, batch normalization layers can be easily added using the `torch.nn.BatchNorm` module.\n",
    "\n",
    "#### **Distillation**\n",
    "\n",
    "**Model distillation** is a technique where a smaller, more efficient model (student) is trained to mimic the outputs of a larger, more complex model (teacher). By training the smaller model to match the predictions of the larger model, distillation allows for significant reductions in model size and computational requirements, without sacrificing much accuracy. This method is widely used in scenarios where models need to be deployed on edge devices with limited computational power.\n",
    "\n",
    "### **Pruning**\n",
    "\n",
    "**Model pruning** is a method of reducing the size of a neural network by removing less important connections (weights) in the network. Pruning can be done in various ways:\n",
    "- **Weight pruning**: Eliminating individual weights that contribute the least to the model's predictions.\n",
    "- **Unit pruning**: Removing entire neurons or filters that have little impact on the overall model performance.\n",
    "\n",
    "Pruning helps reduce model size and inference time, making the model more efficient without drastically affecting its accuracy. In PyTorch, model pruning can be implemented using built-in tools like `torch.nn.utils.prune`, which supports different pruning techniques such as unstructured and structured pruning.\n",
    "\n",
    "### **Knowledge distillation**\n",
    "\n",
    "Another technique for optimization is **knowledge distillation**, where a large, complex model (teacher) is used to train a smaller model (student) by transferring its learned knowledge. The smaller model mimics the behavior of the larger one, retaining much of its performance while being lighter and faster. This is especially useful when deploying models to environments with constrained resources.\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Model optimization in PyTorch involves a combination of techniques to improve the performance and efficiency of models. From tuning hyperparameters and selecting the right optimizer to using advanced techniques like pruning and distillation, each method contributes to reducing resource usage and improving model generalization. Careful optimization ensures that models are not only accurate but also efficient and scalable for real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Maths**\n",
    "\n",
    "#### **Hyperparameter tuning**\n",
    "\n",
    "Hyperparameter tuning involves optimizing variables such as learning rate, batch size, and weight decay to achieve the best model performance. One of the most critical hyperparameters is the learning rate $ \\eta $, which controls the size of the steps taken during gradient descent.\n",
    "\n",
    "The basic update rule for a model’s parameter $ \\theta $ using gradient descent is:\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta \\mathcal{L}(\\theta_t)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ \\theta_t $ represents the model parameters at time step $ t $,\n",
    "- $ \\eta $ is the learning rate,\n",
    "- $ \\nabla_\\theta \\mathcal{L}(\\theta_t) $ is the gradient of the loss function $ \\mathcal{L} $ with respect to the parameters.\n",
    "\n",
    "A large learning rate $ \\eta $ can lead to overshooting the minimum of the loss function, while a small $ \\eta $ results in slow convergence. Hyperparameter tuning attempts to find an optimal $ \\eta $ for faster and stable convergence.\n",
    "\n",
    "#### **Gradient clipping**\n",
    "\n",
    "Gradient clipping is a technique used to prevent exploding gradients, a common problem in deep networks, especially recurrent neural networks (RNNs). The idea is to clip the gradients so that their norm does not exceed a predefined threshold $ \\tau $.\n",
    "\n",
    "Mathematically, if the gradient $ g = \\nabla_\\theta \\mathcal{L}(\\theta) $ exceeds the threshold $ \\tau $, the gradient is rescaled as follows:\n",
    "\n",
    "$$\n",
    "g' = \\frac{\\tau}{\\|g\\|} \\cdot g \\quad \\text{if} \\quad \\|g\\| > \\tau\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ g' $ is the clipped gradient,\n",
    "- $ \\|g\\| $ is the Euclidean norm of the gradient.\n",
    "\n",
    "This ensures that large gradients do not destabilize the training process.\n",
    "\n",
    "#### **Batch normalization**\n",
    "\n",
    "Batch normalization is a technique that stabilizes training by normalizing the inputs to each layer. During training, the input to a layer $ x $ is normalized based on its batch statistics:\n",
    "\n",
    "$$\n",
    "\\hat{x} = \\frac{x - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ \\mu_B $ is the mean of the batch,\n",
    "- $ \\sigma_B^2 $ is the variance of the batch,\n",
    "- $ \\epsilon $ is a small constant to avoid division by zero.\n",
    "\n",
    "The normalized input $ \\hat{x} $ is then scaled and shifted by learnable parameters $ \\gamma $ and $ \\beta $:\n",
    "\n",
    "$$\n",
    "y = \\gamma \\hat{x} + \\beta\n",
    "$$\n",
    "\n",
    "Batch normalization helps the network maintain a stable distribution of inputs across layers, enabling faster convergence and higher learning rates during training. It also mitigates the internal covariate shift, where the distribution of activations changes as model parameters are updated.\n",
    "\n",
    "#### **Early stopping**\n",
    "\n",
    "Early stopping is a regularization technique that halts training when the model’s performance on a validation set starts to degrade, indicating overfitting. During training, we monitor the validation loss $ \\mathcal{L}_{val} $. If the loss stops decreasing after a set number of epochs, training is stopped early.\n",
    "\n",
    "The mathematical condition for early stopping can be expressed as:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{val}(t + k) > \\min_{i=1,\\dots,t} \\mathcal{L}_{val}(i)\n",
    "$$\n",
    "\n",
    "Where $ t $ is the current epoch, $ k $ is the patience parameter, and $ \\mathcal{L}_{val} $ is the validation loss. If the validation loss increases for $ k $ consecutive epochs, the training is stopped to prevent overfitting.\n",
    "\n",
    "#### **Optimizer dynamics**\n",
    "\n",
    "Choosing the right optimizer can have a significant impact on how quickly and efficiently a model converges. Common optimizers such as SGD, Adam, and RMSProp have different mathematical foundations.\n",
    "\n",
    "##### **Stochastic Gradient Descent (SGD)**\n",
    "\n",
    "SGD updates the model parameters using the gradient of the loss function with respect to the parameters:\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta \\mathcal{L}(\\theta_t)\n",
    "$$\n",
    "\n",
    "SGD works well for convex problems but may struggle with more complex, non-convex loss landscapes due to its tendency to get stuck in local minima or saddle points.\n",
    "\n",
    "##### **Adam optimizer**\n",
    "\n",
    "Adam combines ideas from both momentum and adaptive learning rate methods. The update rule for Adam involves two moving averages:\n",
    "- The first moment estimate (mean of the gradients):\n",
    "  $$\n",
    "  m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t\n",
    "  $$\n",
    "- The second moment estimate (uncentered variance of the gradients):\n",
    "  $$\n",
    "  v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2\n",
    "  $$\n",
    "\n",
    "Where $ g_t $ is the gradient at time step $ t $, and $ \\beta_1 $, $ \\beta_2 $ are hyperparameters controlling the decay rates of the moment estimates. The parameters are updated as follows:\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
    "$$\n",
    "\n",
    "Where $ \\hat{m}_t $ and $ \\hat{v}_t $ are bias-corrected estimates of the first and second moments.\n",
    "\n",
    "Adam is particularly useful for tasks with noisy gradients or non-stationary objectives due to its adaptive learning rates.\n",
    "\n",
    "#### **Model pruning**\n",
    "\n",
    "Pruning reduces the number of parameters in a neural network by removing connections (weights) or units (neurons) that contribute minimally to the model’s output. The idea is to minimize the model’s complexity without significantly reducing its performance.\n",
    "\n",
    "Let $ \\theta $ represent the model’s parameters. In pruning, we define a pruning threshold $ \\tau $ and remove any parameter $ \\theta_i $ where:\n",
    "\n",
    "$$\n",
    "|\\theta_i| < \\tau\n",
    "$$\n",
    "\n",
    "After pruning, the remaining parameters are fine-tuned, and the model can retain most of its performance while becoming smaller and faster to evaluate.\n",
    "\n",
    "Pruning can be applied at different levels:\n",
    "- **Unstructured pruning**: Removes individual weights based on their magnitude.\n",
    "- **Structured pruning**: Removes entire neurons, filters, or layers.\n",
    "\n",
    "#### **Distillation**\n",
    "\n",
    "Distillation is a process where a smaller model (student) learns to mimic the outputs of a larger, pre-trained model (teacher). The student is trained using a combination of the ground-truth labels and the teacher’s soft predictions.\n",
    "\n",
    "Let $ p_{\\text{teacher}}(y \\mid x) $ and $ p_{\\text{student}}(y \\mid x) $ represent the output probabilities of the teacher and student models, respectively. The student model is trained to minimize the following loss:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{distill}} = (1 - \\alpha) \\mathcal{L}_{\\text{CE}} + \\alpha \\mathcal{L}_{\\text{KL}}(p_{\\text{teacher}}, p_{\\text{student}})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ \\mathcal{L}_{\\text{CE}} $ is the cross-entropy loss between the student’s predictions and the true labels,\n",
    "- $ \\mathcal{L}_{\\text{KL}} $ is the Kullback-Leibler divergence between the teacher and student model outputs,\n",
    "- $ \\alpha $ controls the trade-off between the two losses.\n",
    "\n",
    "By learning from the teacher’s softened outputs, the student model can achieve high performance with fewer parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q1: How do you install the necessary libraries for model optimization in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q2: How do you import the required PyTorch modules for profiling, pruning, and using mixed precision?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q3: How do you configure the environment to use GPU or multi-GPU setups for efficient model optimization in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile memory usage and performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q4: How do you use PyTorch’s `torch.utils.benchmark` to profile memory usage and track performance?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q5: How do you measure the execution time of different layers in a neural network model using PyTorch’s profiler?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q6: How do you monitor GPU utilization during model training and identify performance bottlenecks?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using mixed precision training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q7: How do you implement automatic mixed precision (AMP) in PyTorch using `torch.cuda.amp`?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q8: How do you modify the training loop to enable mixed precision training for faster computation?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q9: How do you manage and log memory usage when using mixed precision training?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning neural network models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q10: How do you perform unstructured pruning using PyTorch’s `torch.nn.utils.prune` module?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q11: How do you prune entire layers (structured pruning) and evaluate the impact on model performance?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q12: How do you fine-tune a pruned model to recover lost accuracy?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying layer fusion for optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q13: How do you fuse convolution, batch normalization, and ReLU layers in a PyTorch model using `torch.nn.utils.fuse`?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q14: How do you benchmark the performance of a model before and after applying layer fusion?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q15: How do you visualize and analyze the computational benefits of layer fusion in a neural network?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing model checkpoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q16: How do you save PyTorch model checkpoints in a reduced precision format (e.g., `float16`) to save disk space?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q17: How do you use `torch.save` with `state_dict()` to store a more optimized model checkpoint?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q18: How do you load and convert a previously saved model checkpoint to use lower precision parameters?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using model parallelism\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q19: How do you implement model parallelism in PyTorch using `torch.nn.DataParallel` to train models across multiple GPUs?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q20: How do you implement distributed data parallelism using `torch.nn.parallel.DistributedDataParallel` for large-scale training?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q21: How do you split a model into segments and distribute them across multiple devices for training using model parallelism?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the optimized model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q22: How do you evaluate the accuracy and performance of a model optimized with mixed precision compared to the original model?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q23: How do you measure the inference time of a model before and after applying pruning?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q24: How do you compare the memory usage of a model before and after applying pruning and mixed precision training?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with different optimization techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q25: How do you experiment with different percentages of pruning (e.g., 20%, 50%) and observe the effect on model accuracy?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q26: How do you tune the learning rate and batch size while using mixed precision training to maximize model performance?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q27: How do you combine pruning with mixed precision training, and how does it affect training time and memory usage?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q28: How do you experiment with fusing different types of layers (e.g., linear and activation layers) for performance improvements?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
