{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Understanding self-attention](#understanding-self-attention)\n",
    "2. [Setting up the environment](#setting-up-the-environment)\n",
    "3. [Defining the input data](#defining-the-input-data)\n",
    "4. [Implementing scaled dot-product attention](#implementing-scaled-dot-product-attention)\n",
    "5. [Building multi-head self-attention](#building-multi-head-self-attention)\n",
    "6. [Building the position-wise feed-forward network](#building-the-position-wise-feed-forward-network)\n",
    "7. [Applying self-attention to a transformer block](#applying-self-attention-to-a-transformer-block)\n",
    "8. [Training the self-attention mechanism](#training-the-self-attention-mechanism)\n",
    "9. [Evaluating the self-attention model](#evaluating-the-self-attention-model)\n",
    "10. [Visualizing attention weights](#visualizing-attention-weights)\n",
    "11. [Experimenting with hyperparameters](#experimenting-with-hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Key concepts**\n",
    "Self-attention is a mechanism that allows a model to dynamically weigh the importance of different parts of an input sequence when processing each element. Unlike traditional approaches that rely on fixed-sized context windows, self-attention enables models to capture dependencies across all positions in a sequence, making it especially powerful for tasks with long-range relationships.\n",
    "\n",
    "Key components of self-attention include:\n",
    "- **Query, Key, and Value Vectors**: Representations of each input element used to compute attention scores and weighted outputs.\n",
    "- **Attention Scores**: Measure the relevance of each element in the sequence with respect to the current position, typically using a dot-product or scaled dot-product method.\n",
    "- **Weighted Aggregation**: Combines all elements of the sequence based on their attention scores, producing context-aware representations.\n",
    "- **Multi-Head Attention**: Extends self-attention by using multiple attention mechanisms in parallel to capture diverse relationships.\n",
    "\n",
    "Self-attention forms the foundation of Transformer architectures, which have revolutionized fields like natural language processing and computer vision.\n",
    "\n",
    "### **Applications**\n",
    "Self-attention is central to many modern deep learning models, enabling applications such as:\n",
    "- **Natural language processing (NLP)**: Powering models like BERT, GPT, and Transformer-based translation systems.\n",
    "- **Image processing**: Capturing spatial relationships in tasks like object detection and image segmentation.\n",
    "- **Speech recognition**: Modeling dependencies in audio sequences for transcription tasks.\n",
    "- **Time-series analysis**: Understanding dependencies across long temporal data for forecasting or anomaly detection.\n",
    "\n",
    "### **Advantages**\n",
    "- **Global context**: Considers all positions in the sequence simultaneously, capturing long-range dependencies.\n",
    "- **Scalability**: Works well with variable-length inputs and outputs.\n",
    "- **Flexibility**: Adapts to diverse data modalities, including text, images, and audio.\n",
    "- **Parallelization**: Unlike recurrent methods, self-attention allows for parallel computation, significantly speeding up training.\n",
    "\n",
    "### **Challenges**\n",
    "- **Computational cost**: Scales quadratically with input sequence length, making it resource-intensive for very long sequences.\n",
    "- **Memory usage**: Requires substantial memory for large inputs due to the attention matrix.\n",
    "- **Dependency on large datasets**: Performs best when trained on extensive and diverse datasets.\n",
    "- **Complexity**: Incorporates many components, requiring careful implementation and tuning for optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q1: How do you install the necessary libraries for building and training self-attention models in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# !pip install numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q2: How do you import the required modules for building attention mechanisms and handling data in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q3: How do you set up the environment to utilize a GPU for training self-attention models in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the input data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q4: How do you define sequence data, such as tokenized text, to be used as input for the self-attention mechanism?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10\n",
    "seq_len = 6\n",
    "batch_size = 4\n",
    "\n",
    "input_seq = torch.randint(0, vocab_size, (batch_size, seq_len)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q5: How do you preprocess and batch the input data to feed into the self-attention model?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 32\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim).to(device)\n",
    "embedded_input = embedding(input_seq)  # shape: (batch_size, seq_len, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q6: How do you create a DataLoader in PyTorch to load batches of sequential data for training?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummySeqDataset(Dataset):\n",
    "    def __init__(self, num_samples=100):\n",
    "        self.data = [torch.randint(0, vocab_size, (seq_len,)) for _ in range(num_samples)]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DummySeqDataset()\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing scaled dot-product attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q7: How do you implement the function for scaled dot-product attention in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "    d_k = q.size(-1)\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))  # compute raw scores\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, float('-inf'))  # apply mask\n",
    "    attn_weights = F.softmax(scores, dim=-1)  # normalize\n",
    "    return torch.matmul(attn_weights, v), attn_weights  # weighted sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q8: How do you calculate the attention scores by computing the dot product of the query and key matrices?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn(batch_size, seq_len, embedding_dim).to(device)\n",
    "k = torch.randn(batch_size, seq_len, embedding_dim).to(device)\n",
    "v = torch.randn(batch_size, seq_len, embedding_dim).to(device)\n",
    "scores = torch.matmul(q, k.transpose(-2, -1))  # shape: (batch_size, seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q9: How do you apply softmax to normalize the attention scores in the scaled dot-product attention mechanism?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights = F.softmax(scores, dim=-1)  # shape: (batch_size, seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q10: How do you compute the final output of the attention mechanism by multiplying the attention scores with the value matrix?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output = torch.matmul(attn_weights, v)  # shape: (batch_size, seq_len, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building multi-head self-attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q11: How do you define the architecture for multi-head self-attention using `torch.nn.Module` in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        self.qkv_proj = nn.Linear(embed_dim, embed_dim * 3)\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        qkv = self.qkv_proj(x)  # shape: (batch_size, seq_len, 3 * embed_dim)\n",
    "        qkv = qkv.reshape(batch_size, seq_len, 3, self.num_heads, self.head_dim)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32).to(x.device))\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_output = torch.matmul(attn_weights, v)\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().reshape(batch_size, seq_len, self.embed_dim)\n",
    "        return self.out_proj(attn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q12: How do you split the input into multiple heads and perform scaled dot-product attention for each head?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see Q11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q13: How do you concatenate the outputs of the multiple attention heads and apply a final linear transformation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see Q11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the position-wise feed-forward network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q14: How do you define the position-wise feed-forward network using `torch.nn.Linear` layers in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, embed_dim, ff_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(embed_dim, ff_dim)\n",
    "        self.fc2 = nn.Linear(ff_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.relu(self.fc1(x)))  # apply non-linearity and projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q15: How do you apply the feed-forward network to each position in the sequence independently?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see Q14's forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q16: How do you add a non-linearity between the linear layers in the feed-forward network?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see Q14's forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying self-attention to a transformer block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q17: How do you combine multi-head self-attention with layer normalization and residual connections in a transformer block?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ff = PositionwiseFeedForward(embed_dim, ff_dim)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm1(x))  # residual connection after norm and attn\n",
    "        x = x + self.ff(self.norm2(x))  # residual connection after norm and ffn\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q18: How do you implement the forward pass of the transformer block, including both self-attention and feed-forward layers?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see Q17's forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q19: How do you stack multiple transformer blocks to create a deep self-attention model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, ff_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.layers = nn.ModuleList([TransformerBlock(embed_dim, num_heads, ff_dim) for _ in range(num_layers)])\n",
    "        self.classifier = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the self-attention mechanism\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q20: How do you define the loss function for training a self-attention model in PyTorch?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q21: How do you set up the optimizer to update the parameters of the self-attention model during training?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelfAttentionModel(vocab_size, 32, 4, 64, 2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q22: How do you implement the training loop for the self-attention mechanism, including forward pass, loss calculation, and backpropagation?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, dataloader, optimizer, criterion, epochs=5):\n",
    "    model.train()\n",
    "    all_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch)\n",
    "            loss = criterion(output.view(-1, vocab_size), batch.view(-1))  # flatten both\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        all_losses.append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}\")\n",
    "    return all_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q23: How do you track and log the training loss over epochs to monitor the performance of the self-attention model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 1.5133\n",
      "Epoch 2: Loss = 0.3226\n",
      "Epoch 3: Loss = 0.0542\n",
      "Epoch 4: Loss = 0.0201\n",
      "Epoch 5: Loss = 0.0117\n",
      "Epoch 6: Loss = 0.0080\n",
      "Epoch 7: Loss = 0.0058\n",
      "Epoch 8: Loss = 0.0045\n",
      "Epoch 9: Loss = 0.0035\n",
      "Epoch 10: Loss = 0.0029\n"
     ]
    }
   ],
   "source": [
    "losses = train_loop(model, train_loader, optimizer, criterion, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the self-attention model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q24: How do you evaluate the self-attention model on validation or test data after training?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch)\n",
    "            loss = criterion(output.view(-1, vocab_size), batch.view(-1))\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0026\n"
     ]
    }
   ],
   "source": [
    "val_loss = evaluate(model, train_loader, criterion)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q25: How do you calculate the accuracy or other metrics to assess the modelâ€™s performance?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch)\n",
    "            preds = output.argmax(dim=-1)\n",
    "            total += batch.numel()\n",
    "            correct += (preds == batch).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(model, train_loader)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q26: How do you implement a function to perform inference using the trained self-attention model on new input sequences?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, input_seq):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_seq = input_seq.to(device)\n",
    "        output = model(input_seq)\n",
    "        return output.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [[5, 0, 6, 6, 4, 0]]\n",
      "Predicted: [[5, 0, 6, 6, 4, 0]]\n"
     ]
    }
   ],
   "source": [
    "new_input = torch.randint(0, vocab_size, (1, seq_len)).to(device)  # dummy input sequence\n",
    "predicted_output = infer(model, new_input)\n",
    "print(\"Input:\", new_input.cpu().tolist())\n",
    "print(\"Predicted:\", predicted_output.cpu().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing attention weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q27: How do you extract attention weights from the model to analyze how the self-attention mechanism focuses on different parts of the input sequence?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        self.qkv_proj = nn.Linear(embed_dim, embed_dim * 3)\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x, return_weights=False):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        qkv = self.qkv_proj(x).reshape(batch_size, seq_len, 3, self.num_heads, self.head_dim)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32).to(x.device))\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_output = torch.matmul(attn_weights, v)\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().reshape(batch_size, seq_len, self.embed_dim)\n",
    "        if return_weights:\n",
    "            return self.out_proj(attn_output), attn_weights\n",
    "        return self.out_proj(attn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ff = PositionwiseFeedForward(embed_dim, ff_dim)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x, return_weights=False):\n",
    "        if return_weights:\n",
    "            attn_out, attn_weights = self.attn(self.norm1(x), return_weights=True)\n",
    "            x = x + attn_out\n",
    "            x = x + self.ff(self.norm2(x))\n",
    "            return x, attn_weights\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.ff(self.norm2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, ff_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.layers = nn.ModuleList([TransformerBlock(embed_dim, num_heads, ff_dim) for _ in range(num_layers)])\n",
    "        self.classifier = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, return_weights=False):\n",
    "        x = self.embedding(x)\n",
    "        attn_weights_all = []\n",
    "        for layer in self.layers:\n",
    "            if return_weights:\n",
    "                x, attn_weights = layer(x, return_weights=True)\n",
    "                attn_weights_all.append(attn_weights)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        logits = self.classifier(x)\n",
    "        if return_weights:\n",
    "            return logits, attn_weights_all\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted attention weights shape: torch.Size([1, 4, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "model_with_attn = SelfAttentionModel(vocab_size, 32, 4, 64, 2).to(device)\n",
    "model_with_attn.load_state_dict(model.state_dict())  # reuse learned weights\n",
    "\n",
    "_, attn_weights = model_with_attn(new_input, return_weights=True)\n",
    "print(f\"Extracted attention weights shape: {attn_weights[0].shape}\")  # (batch, heads, seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q28: How do you visualize the attention weights as heatmaps to show which tokens or elements the model attends to during the forward pass?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attn_weights):\n",
    "    avg_weights = attn_weights.mean(dim=1)[0].detach().cpu().numpy()  # average over heads\n",
    "    plt.imshow(avg_weights, cmap='viridis')\n",
    "    plt.xlabel(\"Key\")\n",
    "    plt.ylabel(\"Query\")\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Attention Weights Heatmap\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attention(attn_weights[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q29: How do you interpret the attention heatmaps to understand how attention is distributed across layers and heads?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-to-token attention matrix (head 0, first layer):\n",
      "[[0.14181168 0.21660401 0.16228434 0.16228434 0.1004116  0.21660401]\n",
      " [0.0286951  0.35881448 0.1047312  0.1047312  0.04421364 0.35881448]\n",
      " [0.09184583 0.20329945 0.22606175 0.22606175 0.04943175 0.20329945]\n",
      " [0.09184583 0.20329945 0.22606175 0.22606175 0.04943175 0.20329945]\n",
      " [0.19862875 0.03242758 0.04059549 0.04059549 0.6553251  0.03242758]\n",
      " [0.0286951  0.35881448 0.1047312  0.1047312  0.04421364 0.35881448]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Token-to-token attention matrix (head 0, first layer):\")\n",
    "print(attn_weights[0][0, 0].detach().cpu().numpy())  # first sample, first head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q30: How do you experiment with different numbers of attention heads and analyze their effect on model performance and training time?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 2 heads:\n",
      "Epoch 1: Loss = 1.7467\n",
      "Epoch 2: Loss = 0.4300\n",
      "Epoch 3: Loss = 0.0750\n",
      "\n",
      "Training with 4 heads:\n",
      "Epoch 1: Loss = 1.3667\n",
      "Epoch 2: Loss = 0.2976\n",
      "Epoch 3: Loss = 0.0538\n",
      "\n",
      "Training with 8 heads:\n",
      "Epoch 1: Loss = 1.4044\n",
      "Epoch 2: Loss = 0.3385\n",
      "Epoch 3: Loss = 0.0596\n"
     ]
    }
   ],
   "source": [
    "for num_heads in [2, 4, 8]:\n",
    "    temp_model = SelfAttentionModel(vocab_size, 32, num_heads, 64, 2).to(device)\n",
    "    temp_optimizer = torch.optim.Adam(temp_model.parameters(), lr=1e-3)\n",
    "    print(f\"\\nTraining with {num_heads} heads:\")\n",
    "    train_loop(temp_model, train_loader, temp_optimizer, criterion, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q31: How do you adjust the hidden dimension size of the self-attention mechanism and observe its impact on accuracy and convergence?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with embedding dim 16:\n",
      "Epoch 1: Loss = 2.0228\n",
      "Epoch 2: Loss = 1.0745\n",
      "Epoch 3: Loss = 0.4269\n",
      "\n",
      "Training with embedding dim 32:\n",
      "Epoch 1: Loss = 1.3445\n",
      "Epoch 2: Loss = 0.3042\n",
      "Epoch 3: Loss = 0.0556\n",
      "\n",
      "Training with embedding dim 64:\n",
      "Epoch 1: Loss = 1.0269\n",
      "Epoch 2: Loss = 0.0372\n",
      "Epoch 3: Loss = 0.0064\n"
     ]
    }
   ],
   "source": [
    "for embed_dim in [16, 32, 64]:\n",
    "    temp_model = SelfAttentionModel(vocab_size, embed_dim, 4, 64, 2).to(device)\n",
    "    temp_optimizer = torch.optim.Adam(temp_model.parameters(), lr=1e-3)\n",
    "    print(f\"\\nTraining with embedding dim {embed_dim}:\")\n",
    "    train_loop(temp_model, train_loader, temp_optimizer, criterion, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q32: How do you experiment with varying the number of transformer blocks in the model and analyze how it affects the results?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 1 transformer blocks:\n",
      "Epoch 1: Loss = 1.5968\n",
      "Epoch 2: Loss = 0.6041\n",
      "Epoch 3: Loss = 0.1554\n",
      "\n",
      "Training with 2 transformer blocks:\n",
      "Epoch 1: Loss = 1.8826\n",
      "Epoch 2: Loss = 0.4580\n",
      "Epoch 3: Loss = 0.0784\n",
      "\n",
      "Training with 4 transformer blocks:\n",
      "Epoch 1: Loss = 1.1107\n",
      "Epoch 2: Loss = 0.1254\n",
      "Epoch 3: Loss = 0.0233\n"
     ]
    }
   ],
   "source": [
    "for num_layers in [1, 2, 4]:\n",
    "    temp_model = SelfAttentionModel(vocab_size, 32, 4, 64, num_layers).to(device)\n",
    "    temp_optimizer = torch.optim.Adam(temp_model.parameters(), lr=1e-3)\n",
    "    print(f\"\\nTraining with {num_layers} transformer blocks:\")\n",
    "    train_loop(temp_model, train_loader, temp_optimizer, criterion, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q33: How do you tune learning rates and dropout rates to improve the generalization of the self-attention model?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with learning rate 0.0001:\n",
      "Epoch 1: Loss = 2.3815\n",
      "Epoch 2: Loss = 2.1971\n",
      "Epoch 3: Loss = 2.0263\n",
      "\n",
      "Training with learning rate 0.001:\n",
      "Epoch 1: Loss = 1.5310\n",
      "Epoch 2: Loss = 0.3275\n",
      "Epoch 3: Loss = 0.0546\n",
      "\n",
      "Training with learning rate 0.01:\n",
      "Epoch 1: Loss = 0.2920\n",
      "Epoch 2: Loss = 0.0000\n",
      "Epoch 3: Loss = 0.0000\n"
     ]
    }
   ],
   "source": [
    "for lr in [1e-4, 1e-3, 1e-2]:\n",
    "    temp_model = SelfAttentionModel(vocab_size, 32, 4, 64, 2).to(device)\n",
    "    temp_optimizer = torch.optim.Adam(temp_model.parameters(), lr=lr)\n",
    "    print(f\"\\nTraining with learning rate {lr}:\")\n",
    "    train_loop(temp_model, train_loader, temp_optimizer, criterion, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q34: How do you analyze the effect of different activation functions in the feed-forward network on training stability?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForwardAct(nn.Module):\n",
    "    def __init__(self, embed_dim, ff_dim, activation):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(embed_dim, ff_dim)\n",
    "        self.fc2 = nn.Linear(ff_dim, embed_dim)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.activation(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlockAct(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, activation):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ff = PositionwiseFeedForwardAct(embed_dim, ff_dim, activation)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.ff(self.norm2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionModelAct(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, ff_dim, num_layers, activation):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.layers = nn.ModuleList([TransformerBlockAct(embed_dim, num_heads, ff_dim, activation) for _ in range(num_layers)])\n",
    "        self.classifier = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with activation: relu\n",
      "Epoch 1: Loss = 1.7794\n",
      "Epoch 2: Loss = 0.4392\n",
      "Epoch 3: Loss = 0.0693\n",
      "\n",
      "Training with activation: gelu\n",
      "Epoch 1: Loss = 1.7056\n",
      "Epoch 2: Loss = 0.3986\n",
      "Epoch 3: Loss = 0.0597\n",
      "\n",
      "Training with activation: leaky_relu\n",
      "Epoch 1: Loss = 1.5371\n",
      "Epoch 2: Loss = 0.3176\n",
      "Epoch 3: Loss = 0.0527\n"
     ]
    }
   ],
   "source": [
    "for act_fn in [F.relu, F.gelu, F.leaky_relu]:\n",
    "    temp_model = SelfAttentionModelAct(vocab_size, 32, 4, 64, 2, act_fn).to(device)\n",
    "    temp_optimizer = torch.optim.Adam(temp_model.parameters(), lr=1e-3)\n",
    "    print(f\"\\nTraining with activation: {act_fn.__name__}\")\n",
    "    train_loop(temp_model, train_loader, temp_optimizer, criterion, epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
