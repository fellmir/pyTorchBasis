{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and processing in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Understanding data loading and processing in PyTorch](#understanding-data-loading-and-processing-in-pytorch)\n",
    "2. [Setting up the environment](#setting-up-the-environment)\n",
    "3. [Working with datasets and DataLoader](#working-with-datasets-and-dataloader)\n",
    "4. [Data transformations and augmentations](#data-transformations-and-augmentations)\n",
    "5. [Handling different data formats](#handling-different-data-formats)\n",
    "6. [Preprocessing pipelines](#preprocessing-pipelines)\n",
    "7. [Advanced data loading techniques](#advanced-data-loading-techniques)\n",
    "8. [Practical examples and use cases](#practical-examples-and-use-cases)\n",
    "9. [Further exercises](#further-exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding data loading and processing in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Why data loading and processing matter**\n",
    "\n",
    "The performance of a machine learning model heavily relies on the quality and format of the data it receives. Properly loading and preprocessing data ensures that the model can effectively learn from the input data, leading to better generalization and accuracy. Efficient data handling also reduces bottlenecks during training, particularly when working with large datasets or complex models.\n",
    "\n",
    "### **Key concepts**\n",
    "\n",
    "- **Datasets**: PyTorch provides the `torch.utils.data.Dataset` class as an abstract class for handling datasets. Custom datasets can be created by subclassing `Dataset` and overriding two methods: `__len__()` to return the size of the dataset and `__getitem__()` to retrieve a data sample. PyTorch also offers built-in datasets like MNIST, CIFAR-10, and more, which can be easily loaded using `torchvision.datasets`.\n",
    "- **DataLoader**: The `torch.utils.data.DataLoader` class is responsible for loading data in batches, shuffling data, and handling multiprocessing for loading data in parallel. It is highly customizable, allowing for control over batch size, shuffling, and the number of worker threads used for loading.\n",
    "- **Transforms**: Data transformations are essential for normalizing, augmenting, and converting data into the appropriate format for model training. PyTorch’s `torchvision.transforms` module provides a wide range of predefined transformations that can be chained together using `transforms.Compose`. Custom transformations can also be created to fit specific needs.\n",
    "\n",
    "### **Data loading workflow in PyTorch**\n",
    "\n",
    "The typical data loading workflow in PyTorch involves the following steps:\n",
    "\n",
    "- **Defining the dataset**: Whether using a built-in dataset or creating a custom one, the first step is to define the dataset by subclassing `Dataset`. This involves specifying how to access and return individual samples.\n",
    "- **Applying transforms**: Once the dataset is defined, transformations are applied to the data to ensure it is in the correct format for model training. This might include normalization, resizing, cropping, or more advanced augmentations like random rotations or color jitter.\n",
    "- **Creating DataLoader**: With the dataset and transformations in place, the DataLoader is created to handle the batching, shuffling, and parallel loading of data. This is where most of the heavy lifting in terms of data management happens.\n",
    "- **Iterating through data**: Finally, the DataLoader is used in the training loop to iterate through the dataset in batches, feeding data to the model for training or validation.\n",
    "\n",
    "### **Handling large datasets**\n",
    "\n",
    "For large datasets that cannot fit into memory, PyTorch’s DataLoader supports lazy loading, where only a portion of the data is loaded into memory at a time. This is done through the use of custom datasets and careful management of batch sizes and worker threads. Techniques such as data streaming, where data is continuously fed from disk to memory, can also be employed.\n",
    "\n",
    "### **Optimization techniques**\n",
    "\n",
    "Optimizing data loading and processing can have a significant impact on training speed and model performance. Some key techniques include:\n",
    "\n",
    "- **Using multiple workers**: Increasing the number of worker threads in the DataLoader can speed up data loading by parallelizing the process.\n",
    "- **Prefetching data**: Preloading the next batch while the model is training on the current batch can reduce the waiting time between epochs.\n",
    "- **Data augmentation**: Real-time data augmentation during training can increase the diversity of the dataset without the need to store augmented images on disk.\n",
    "\n",
    "### **Common pitfalls and best practices**\n",
    "\n",
    "- **Shuffling data**: Always shuffle the training data to prevent the model from learning the order of the data, which can lead to overfitting.\n",
    "- **Normalizing data**: Proper normalization ensures that the data is on a similar scale, which is crucial for stable and efficient model training.\n",
    "- **Managing data formats**: Ensure that the data is in the correct format (e.g., tensors) before feeding it to the model. PyTorch expects data in the form of tensors, with specific shapes depending on the model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q1: How do you install the necessary libraries for data loading and processing in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# !pip install numpy matplotlib scikit-learn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q2: How do you import the required modules for data handling in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with datasets and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q3: How do you load built-in datasets using `torchvision`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../00-src\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:06<00:00, 1561489.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../00-src\\MNIST\\raw\\train-images-idx3-ubyte.gz to ../00-src\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../00-src\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 116348.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../00-src\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ../00-src\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../00-src\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 2508841.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../00-src\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ../00-src\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../00-src\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4570664.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../00-src\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../00-src\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the MNIST dataset as an example:\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to range [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='../00-src', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='../00-src', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q4: How do you explore the properties of a dataset, such as size and classes, in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 60000\n",
      "Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f'Train dataset size: {len(train_dataset)}')\n",
    "print(f'Test dataset size: {len(test_dataset)}')  # Dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
     ]
    }
   ],
   "source": [
    "print(f'Classes: {train_dataset.classes}')  # Only applicable for datasets that have 'classes' attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample image shape: torch.Size([1, 28, 28])\n",
      "Sample label: 5\n"
     ]
    }
   ],
   "source": [
    "sample_image, sample_label = train_dataset[0]\n",
    "print(f'Sample image shape: {sample_image.shape}')  # Shape of a single sample\n",
    "print(f'Sample label: {sample_label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q5: How do you create a custom dataset class in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass torch.utils.data.Dataset and implement the __len__ and __getitem__ methods:\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):  # Initializes the dataset object with data, labels, and any optional transformations\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):  # Returns the total number of samples\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):  # Retrieves the sample and label at the given index\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q6: How do you implement the `__len__` and `__getitem__` methods for a custom dataset?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q7: How do you use the DataLoader to batch data in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 64\n",
      "Batch size: 64\n",
      "Batch size: 64\n",
      "Batch size: 64\n",
      "Batch size: 64\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)  # Create DataLoader for the custom dataset\n",
    "\n",
    "all_batches = list(train_loader)  # Convert the DataLoader to a list to randomly sample from it\n",
    "\n",
    "sampled_batches = random.sample(all_batches, 5)  # Randomly select five batches\n",
    "\n",
    "for images, labels in sampled_batches:  # Iterate through the sampled batches and print the batch size\n",
    "    print(f'Batch size: {images.size(0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q8: How do you shuffle data using DataLoader in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)  # set the shuffle parameter to True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q9: How do you load data in parallel using multiple workers with DataLoader?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, num_workers=4)  # set the num_workers parameter in DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformations and augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q10: How do you apply basic data transformations, such as normalization, in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalizes each channel to range [-1, 1]\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root='../00-src', train=True, download=True, transform=transform)  # Apply the transform when loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q11: How do you resize and crop images using PyTorch transformations?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to 128x128\n",
    "    transforms.CenterCrop(112),     # Crop the center 112x112\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root='../00-src', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q12: How do you compose multiple transformations using `transforms.Compose` in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize for grayscale images\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root='../00-src', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q13: What are some common data augmentation techniques?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=15),  # Rotate the image by up to 15 degrees\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip the image horizontally with a 50% probability\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Randomly change brightness, contrast, saturation, and hue\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root='../00-src', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../00-src\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=(-0.1, 0.1))\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling different data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q14: How do you load image data from files and directories in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fellm\\AppData\\Local\\Temp\\ipykernel_2496\\4019146405.py:20: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar_ref.extractall(root_dir)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset extracted to ../00-src\\flower_photos\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "root_dir = '../00-src'  # Define the path to the root directory\n",
    "\n",
    "if not os.path.exists(root_dir):\n",
    "    os.makedirs(root_dir)  # Create the directory if it doesn't exist\n",
    "\n",
    "url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"  # URL of a sample dataset (e.g., a small dataset of flowers)\n",
    "tgz_path = os.path.join(root_dir, \"flower_photos.tgz\")\n",
    "\n",
    "urllib.request.urlretrieve(url, tgz_path)  # Download the dataset\n",
    "\n",
    "with tarfile.open(tgz_path, 'r:gz') as tar_ref:\n",
    "    tar_ref.extractall(root_dir)  # Extract the dataset\n",
    "\n",
    "data_dir = os.path.join(root_dir, \"flower_photos\")  # Define the directory containing the images\n",
    "\n",
    "print(f\"Dataset extracted to {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_imgs = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images to 128x128\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize images\n",
    "])\n",
    "\n",
    "dataset_imgs = datasets.ImageFolder(root=data_dir, transform=transform_imgs)  # Load the image data from the directory\n",
    "\n",
    "dataloader_imgs = DataLoader(dataset_imgs, batch_size=32, shuffle=True)  # Create a DataLoader to batch and shuffle the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q15: How do you load and preprocess CSV or tabular data using `pandas` and convert it to tensors?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(root_dir, \"sample_data.csv\")  # Define the path to save the CSV file\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'feature1': [1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "    'feature2': [10.0, 20.0, 30.0, 40.0, 50.0],\n",
    "    'label': [0, 1, 0, 1, 0]\n",
    "})  # Create a sample CSV file\n",
    "df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., 10.],\n",
      "        [ 2., 20.],\n",
      "        [ 3., 30.],\n",
      "        [ 4., 40.],\n",
      "        [ 5., 50.]])\n",
      "tensor([0, 1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(csv_path)  # Load the CSV file using pandas\n",
    "\n",
    "features = torch.tensor(df[['feature1', 'feature2']].values, dtype=torch.float32)\n",
    "labels = torch.tensor(df['label'].values, dtype=torch.long)  # Convert features and labels to tensors\n",
    "\n",
    "print(features)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q16: How do you load and preprocess text data in PyTorch, including tokenization and embedding creation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../00-src\\\\sample_text.txt', <http.client.HTTPMessage at 0x1bc56d6d370>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_path = os.path.join(root_dir, \"sample_text.txt\")\n",
    "\n",
    "url = \"https://www.gutenberg.org/files/11/11-0.txt\"  # Download a sample text file: Alice's Adventures in Wonderland\n",
    "urllib.request.urlretrieve(url, text_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fellm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\fellm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  2,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')  # This will download the punkt tokenizer\n",
    "nltk.download('punkt_tab')  # Add this line to download 'punkt_tab' if needed\n",
    "\n",
    "with open(text_path, 'r', encoding='utf-8') as f:  # Load the text data with the correct encoding\n",
    "    text_data = f.readlines()\n",
    "\n",
    "tokenized_data = [nltk.word_tokenize(line.lower()) for line in text_data]  # Tokenize the text data using nltk\n",
    "\n",
    "counter = Counter([word for line in tokenized_data for word in line])\n",
    "vocab = {word: idx for idx, (word, _) in enumerate(counter.items(), start=1)}  # Build a vocabulary\n",
    "vocab['<unk>'] = 0  # Add an unknown token\n",
    "\n",
    "text_as_tensor = [torch.tensor([vocab.get(word, 0) for word in line], dtype=torch.long) for line in tokenized_data]  # Convert tokens to tensor indices\n",
    "\n",
    "print(text_as_tensor[0])  # Print tensor for the first line of text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q17: What strategies can you use to handle missing data when loading and preprocessing datasets?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values: 9836\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)  # Set random seed for reproducibility\n",
    "\n",
    "num_samples = 10000\n",
    "num_features = 10\n",
    "\n",
    "data = torch.randn(num_samples, num_features)  # Generate random data\n",
    "\n",
    "mask = torch.rand(num_samples, num_features) < 0.1\n",
    "data[mask] = float('nan')\n",
    "\n",
    "print(f\"Number of missing values: {torch.isnan(data).sum().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: torch.Size([10000, 10])\n",
      "Cleaned dataset size: torch.Size([3601, 10])\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows with missing values:\n",
    "rows_with_nan = torch.isnan(data).any(dim=1)\n",
    "\n",
    "cleaned_data = data[~rows_with_nan]  # Drop rows with any NaNs\n",
    "\n",
    "print(f\"Original dataset size: {data.size()}\")\n",
    "print(f\"Cleaned dataset size: {cleaned_data.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values after filling with zero: 0\n"
     ]
    }
   ],
   "source": [
    "# Fill NaNs with zero:\n",
    "data_filled_zero = torch.nan_to_num(data, nan=0.0)\n",
    "\n",
    "print(f\"Number of missing values after filling with zero: {torch.isnan(data_filled_zero).sum().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values after filling with column mean: 0\n"
     ]
    }
   ],
   "source": [
    "# Fill NaNs with the column mean:\n",
    "column_means = torch.nanmean(data, dim=0)\n",
    "\n",
    "column_means_expanded = column_means.unsqueeze(0).expand_as(data)  # Expand the column means to match the data shape\n",
    "\n",
    "data_filled_mean = torch.where(torch.isnan(data), column_means_expanded, data)  # Filling in the mean\n",
    "\n",
    "print(f\"Number of missing values after filling with column mean: {torch.isnan(data_filled_mean).sum().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values after interpolation: 0\n"
     ]
    }
   ],
   "source": [
    "# Interpolating missing data using pandas:\n",
    "data_df = pd.DataFrame(data.numpy())\n",
    "\n",
    "data_interpolated = data_df.interpolate(method='linear', limit_direction='both', axis=0)  # Interpolate missing values with both forward and backward fill for edge cases\n",
    "\n",
    "data_interpolated_tensor = torch.tensor(data_interpolated.values)\n",
    "\n",
    "print(f\"Number of missing values after interpolation: {torch.isnan(data_interpolated_tensor).sum().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values after imputation: 0\n",
      "tensor([[ 1.9269e+00,  1.4873e+00,  9.0072e-01, -2.1055e+00, -4.9533e-04,\n",
      "         -1.2345e+00, -4.3067e-02, -1.6047e+00, -7.5214e-01,  1.6487e+00],\n",
      "        [-3.9248e-01, -1.4036e+00, -7.2788e-01, -5.5943e-01, -7.6884e-01,\n",
      "          7.6245e-01,  1.6423e+00, -1.5960e-01, -4.9740e-01,  4.3959e-01],\n",
      "        [-7.5813e-01,  1.0783e+00,  8.0080e-01,  1.6806e+00,  1.2791e+00,\n",
      "          1.2964e+00,  6.1047e-01,  1.3347e+00, -2.3162e-01,  4.1759e-02],\n",
      "        [-2.5158e-01,  8.5986e-01, -1.3847e+00, -8.7124e-01, -2.2337e-01,\n",
      "          1.7174e+00,  3.1888e-01, -4.2452e-01,  3.0572e-01, -7.7459e-01],\n",
      "        [-1.5576e+00,  9.9564e-01, -8.7979e-01,  1.3268e-02, -1.2742e+00,\n",
      "          2.1228e+00,  1.0641e-02, -4.8791e-01, -9.1382e-01,  1.4074e-02]])\n"
     ]
    }
   ],
   "source": [
    "# Imputation with sklearn:\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "data_np = data.numpy()\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')  # Initialize the SimpleImputer to fill missing values with the mean of each column\n",
    "\n",
    "data_imputed_np = imputer.fit_transform(data_np)  # Fit the imputer on the data and transform it to fill in the missing values\n",
    "\n",
    "data_imputed_tensor = torch.tensor(data_imputed_np)  # Convert the imputed NumPy array back to a PyTorch tensor\n",
    "\n",
    "print(f\"Number of missing values after imputation: {torch.isnan(data_imputed_tensor).sum().item()}\")  # Print the number of missing values after imputation\n",
    "\n",
    "print(data_imputed_tensor[:5])  # Print the first 5 rows of the imputed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q18: How do you build a preprocessing pipeline that integrates transformations and augmentations in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation pipeline:\n",
    "transform_pipeline = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip the image horizontally\n",
    "    transforms.RandomRotation(degrees=15),  # Randomly rotate the image by up to 15 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Randomly adjust brightness, contrast, etc.\n",
    "    transforms.Resize((128, 128)),  # Resize the image to 128x128\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the image\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With images in a directory structure compatible with ImageFolder:\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "dataset = ImageFolder(root='../00-src/flower_photos', transform=transform_pipeline)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate with model training\n",
    "# for images, labels in dataloader:\n",
    "    # Forward pass: Compute predicted y by passing x to the model.\n",
    "    # outputs = model(images)\n",
    "    # Compute loss, gradients, and update model parameters here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q19: How do you manage data flow from raw input to a model-ready format in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = ImageFolder(root='../00-src/flower_photos')  # Load raw data\n",
    "\n",
    "transform_pipeline = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "preprocessed_data = ImageFolder(root='../00-src/flower_photos', transform=transform_pipeline)  # Apply transformations\n",
    "\n",
    "dataloader = DataLoader(preprocessed_data, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass through the model:\n",
    "for batch in dataloader:\n",
    "    images, labels = batch\n",
    "    # Pass the batch to the model\n",
    "    # outputs = model(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q20: How do you create and use custom collate functions in PyTorch to handle variable-length inputs?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):  # Define a collate function\n",
    "    sequences, labels = zip(*batch)  # Unzip the batch into separate sequences and labels\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)  # Pad sequences to the same length\n",
    "    labels = torch.tensor(labels)  # Stack labels into a tensor\n",
    "    return padded_sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, collate_fn=collate_fn, shuffle=True)  # Use the collate function with DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed batches into the model:\n",
    "for batch in dataloader:\n",
    "    sequences, labels = batch\n",
    "    # Pass the batch to the model\n",
    "    # outputs = model(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q21: How do you manage different data structures in a preprocessing pipeline?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fellm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "text_path = '../00-src/sample_text.txt'\n",
    "with open(text_path, 'r', encoding='utf-8') as f:\n",
    "    text_data = f.readlines()\n",
    "\n",
    "# Simple text processing example:\n",
    "nltk.download('punkt')\n",
    "def text_transform(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    return torch.tensor([len(tokens)])  # Simple feature: number of tokens\n",
    "\n",
    "text_data_processed = [text_transform(text) for text in text_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "csv_path = '../00-src/sample_data.csv'\n",
    "tabular_df = pd.read_csv(csv_path)  # Load the tabular data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "tabular_data_processed = scaler.fit_transform(tabular_df[['feature1', 'feature2']])  # Normalize the tabular data\n",
    "\n",
    "tabular_data_processed = torch.tensor(tabular_data_processed, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_processed = torch.randn(100, 3, 128, 128)  # Create dummy image data: 100 RGB images, 128x128 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine pipelines:\n",
    "from itertools import cycle\n",
    "\n",
    "class MultiModalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_data, tabular_data, text_data):\n",
    "        self.image_data = image_data\n",
    "        self.tabular_data = tabular_data\n",
    "        self.text_data = text_data\n",
    "        self.max_length = len(image_data)\n",
    "        \n",
    "        if len(tabular_data) < self.max_length:\n",
    "            self.tabular_data = list(cycle(tabular_data))[:self.max_length]\n",
    "        if len(text_data) < self.max_length:\n",
    "            self.text_data = list(cycle(text_data))[:self.max_length]  # Extend smaller datasets to match the largest one\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.image_data[idx]\n",
    "        tabular = self.tabular_data[idx]\n",
    "        text = self.text_data[idx]\n",
    "\n",
    "        return image, tabular, text\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.max_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DataLoader with the combined dataset (it's too big - memory error!)\n",
    "# dataset = MultiModalDataset(image_data_processed, tabular_data_processed, text_data_processed)\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# for batch in dataloader:\n",
    "#     images, tabular_data, text_data = batch\n",
    "    # print(images.shape, tabular_data.shape, text_data.shape)\n",
    "    # Pass to a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced data loading techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q22: What strategies can you use to work with large datasets that do not fit in memory in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 50000 samples in 'g:\\My Drive\\Pro\\Portfólios\\git\\pyTorchBasis\\00-basic-examples\\00-src\\large_dataset'\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = os.path.abspath('../00-src/large_dataset')\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "num_samples = 50000  # Number of samples in the dataset\n",
    "image_shape = (3, 128, 128)  # Simulating 128x128 RGB images\n",
    "num_tabular_features = 10  # Number of features in tabular data\n",
    "text_length = 50  # Length of the text sequences (number of tokens)\n",
    "\n",
    "# Creating the dataset (it'll take a while!):\n",
    "for i in range(num_samples):\n",
    "    image = torch.randn(image_shape)\n",
    "    torch.save(image, os.path.join(dataset_dir, f'image_{i}.pt'))  # Simulate image data\n",
    "\n",
    "    tabular = torch.randn(num_tabular_features)\n",
    "    torch.save(tabular, os.path.join(dataset_dir, f'tabular_{i}.pt'))  # Simulate tabular data\n",
    "\n",
    "    text = torch.randint(0, 10000, (text_length,))  # Random tokens between 0 and 9999\n",
    "    torch.save(text, os.path.join(dataset_dir, f'text_{i}.pt'))  # Simulate text data\n",
    "\n",
    "print(f\"Created {num_samples} samples in '{dataset_dir}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fellm\\AppData\\Local\\Temp\\ipykernel_2496\\1999774282.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image = torch.load(os.path.join(self.dataset_dir, f'image_{idx}.pt'))\n",
      "C:\\Users\\fellm\\AppData\\Local\\Temp\\ipykernel_2496\\1999774282.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tabular = torch.load(os.path.join(self.dataset_dir, f'tabular_{idx}.pt'))\n",
      "C:\\Users\\fellm\\AppData\\Local\\Temp\\ipykernel_2496\\1999774282.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  text = torch.load(os.path.join(self.dataset_dir, f'text_{idx}.pt'))\n"
     ]
    }
   ],
   "source": [
    "# Use DataLoader with the LargeDataset:\n",
    "class LargeDataset(Dataset):\n",
    "    def __init__(self, dataset_dir):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.num_samples = len([name for name in os.listdir(dataset_dir) if name.startswith('image_')])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:  # Load data lazily from disk\n",
    "            image = torch.load(os.path.join(self.dataset_dir, f'image_{idx}.pt'))\n",
    "            tabular = torch.load(os.path.join(self.dataset_dir, f'tabular_{idx}.pt'))\n",
    "            text = torch.load(os.path.join(self.dataset_dir, f'text_{idx}.pt'))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data at index {idx}: {e}\")\n",
    "            raise\n",
    "        return image, tabular, text\n",
    "\n",
    "dataset = LargeDataset('../00-src/large_dataset')\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)  # Try with no multiprocessing first\n",
    "\n",
    "for batch in dataloader:  # If it works fine without multiprocessing, gradually increase num_workers\n",
    "    images, tabular_data, text_data = batch\n",
    "    # print(images.shape, tabular_data.shape, text_data.shape)\n",
    "    # Add model training code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q23: How do you implement lazy loading to load data as needed in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q24: How can you speed up data loading by caching preprocessed data in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fellm\\AppData\\Local\\Temp\\ipykernel_2496\\3717231156.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image = torch.load(os.path.join(self.dataset_dir, f'image_{idx}.pt'))\n",
      "C:\\Users\\fellm\\AppData\\Local\\Temp\\ipykernel_2496\\3717231156.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tabular = torch.load(os.path.join(self.dataset_dir, f'tabular_{idx}.pt'))\n",
      "C:\\Users\\fellm\\AppData\\Local\\Temp\\ipykernel_2496\\3717231156.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  text = torch.load(os.path.join(self.dataset_dir, f'text_{idx}.pt'))\n"
     ]
    }
   ],
   "source": [
    "class CachedLargeDataset(Dataset):  # Use DataLoader with CachedLargeDataset\n",
    "    def __init__(self, dataset_dir, cache_dir):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.cache_dir = cache_dir\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        self.num_samples = len([name for name in os.listdir(dataset_dir) if 'image_' in name])\n",
    "\n",
    "    def preprocess_and_cache(self, idx):\n",
    "        cache_path = os.path.join(self.cache_dir, f'cache_{idx}.pt')\n",
    "        if os.path.exists(cache_path):\n",
    "            return torch.load(cache_path)\n",
    "\n",
    "        image = torch.load(os.path.join(self.dataset_dir, f'image_{idx}.pt'))\n",
    "        tabular = torch.load(os.path.join(self.dataset_dir, f'tabular_{idx}.pt'))\n",
    "        text = torch.load(os.path.join(self.dataset_dir, f'text_{idx}.pt'))  # Otherwise, load the raw data and preprocess it\n",
    "\n",
    "        image = (image - image.mean()) / image.std()\n",
    "        preprocessed_data = (image, tabular, text)\n",
    "        torch.save(preprocessed_data, cache_path)\n",
    "        return preprocessed_data  # Example of a simple preprocessing step\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.preprocess_and_cache(idx)\n",
    "\n",
    "os.makedirs('../00-src/cache_dir', exist_ok=True)\n",
    "\n",
    "cached_dataset = CachedLargeDataset('../00-src/large_dataset', '../00-src/cache_dir')\n",
    "cached_dataloader = DataLoader(cached_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "for batch in cached_dataloader:\n",
    "    images, tabular_data, text_data = batch\n",
    "    # Process the batch\n",
    "    # print(images.shape, tabular_data.shape, text_data.shape)\n",
    "    # Add model training code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 'g:\\My Drive\\Pro\\Portfólios\\git\\pyTorchBasis\\00-basic-examples\\00-src\\large_dataset'\n",
      "Deleted 'g:\\My Drive\\Pro\\Portfólios\\git\\pyTorchBasis\\00-basic-examples\\00-src\\cache_dir'\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "dataset_dir = os.path.abspath('../00-src/large_dataset')\n",
    "cache_dir = os.path.abspath('../00-src/cache_dir')\n",
    "\n",
    "if os.path.exists(dataset_dir):\n",
    "    shutil.rmtree(dataset_dir)\n",
    "    print(f\"Deleted '{dataset_dir}'\")\n",
    "\n",
    "if os.path.exists(cache_dir):\n",
    "    shutil.rmtree(cache_dir)\n",
    "    print(f\"Deleted '{cache_dir}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical examples and use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q25: How do you prepare image data for classification tasks using CNNs in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_pipeline = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images to 128x128\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize images\n",
    "])\n",
    "\n",
    "dataset_dir = '../00-src/flower_photos'\n",
    "dataset = ImageFolder(root=dataset_dir, transform=transform_pipeline)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the DataLoader in training\n",
    "# for images, labels in dataloader:\n",
    "    # Pass the images to your CNN model\n",
    "    # outputs = model(images)\n",
    "    # Compute loss, backpropagate, and update model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q26: How do you preprocess text data for NLP tasks in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = '../00-src/sample_text.txt'\n",
    "with open(text_path, 'r', encoding='utf-8') as f:\n",
    "    text_data = f.readlines()\n",
    "\n",
    "tokenizer = nltk.word_tokenize  # Tokenize the text data using nltk\n",
    "tokenized_data = [tokenizer(line.lower()) for line in text_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter([word for line in tokenized_data for word in line])\n",
    "vocab = {word: idx for idx, (word, _) in enumerate(counter.items(), start=1)}\n",
    "vocab['<unk>'] = 0  # Add an unknown token\n",
    "\n",
    "text_as_tensor = [torch.tensor([vocab.get(word, 0) for word in line], dtype=torch.long) for line in tokenized_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):  # Create a custom (text) dataset\n",
    "    def __init__(self, text_tensor):\n",
    "        self.text_tensor = text_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_tensor)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.text_tensor[idx]\n",
    "\n",
    "text_dataset = TextDataset(text_as_tensor)\n",
    "text_dataloader = DataLoader(text_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q27: How do you work with multi-modal data, combining image and text data, in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalDataset(Dataset):  # Create a multi-modal dataset class\n",
    "    def __init__(self, image_dataset, text_tensors):\n",
    "        self.image_dataset = image_dataset\n",
    "        self.text_tensors = text_tensors\n",
    "\n",
    "    def __len__(self):  # Ensure the dataset is as long as the shorter dataset to prevent indexing errors\n",
    "        return min(len(self.image_dataset), len(self.text_tensors))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image, label = self.image_dataset[idx]  # Get the image and its label from the image dataset\n",
    "\n",
    "        text_tensor = self.text_tensors[idx % len(self.text_tensors)]  # Get the corresponding text data by cycling through it if necessary\n",
    "\n",
    "        return image, text_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_modal_dataset = MultiModalDataset(image_dataset=image_dataset, text_tensors=text_as_tensor)  # Create the multi-modal dataset\n",
    "\n",
    "multi_modal_dataloader = DataLoader(multi_modal_dataset, batch_size=32, shuffle=True, num_workers=4)  # Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of the multi-modal DataLoader (it takes a long while):\n",
    "# for images, texts, labels in multi_modal_dataloader:\n",
    "    # Here you can process images and texts together in your model\n",
    "    # print(f'Images shape: {images.shape}')\n",
    "    # print(f'Texts shape: {texts.shape}')\n",
    "    # print(f'Labels shape: {labels.shape}')\n",
    "    # Add model training code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared all contents of 'g:\\My Drive\\Pro\\Portfólios\\git\\pyTorchBasis\\00-basic-examples\\00-src'\n"
     ]
    }
   ],
   "source": [
    "src_folder = os.path.abspath('../00-src')\n",
    "\n",
    "if os.path.exists(src_folder):\n",
    "    for filename in os.listdir(src_folder):  # Iterate over all files and directories within the folder\n",
    "        file_path = os.path.join(src_folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # Remove the file or symbolic link\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)  # Remove the directory and all its contents\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "    print(f\"Cleared all contents of '{src_folder}'\")\n",
    "else:\n",
    "    print(f\"The directory '{src_folder}' does not exist\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
