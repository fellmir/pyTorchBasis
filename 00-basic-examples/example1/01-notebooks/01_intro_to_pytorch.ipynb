{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch\n",
    "\n",
    "Welcome to the `01_intro_to_pytorch` notebook. This is part of a portfolio designed to showcase foundational PyTorch concepts and techniques that will be utilized in later projects. \n",
    "\n",
    "Here, I cover essential topics such as setting up the environment, working with tensors, leveraging GPU acceleration, and implementing automatic differentiation. Through various exercises, this notebook will show how to create and manipulate tensors, build and train simple neural networks, and evaluate model performance. \n",
    "\n",
    "This notebook lays the groundwork for more advanced PyTorch applications in subsequent projects.\n",
    "\n",
    "Also, keep in mind that these notebooks following a \"question-and-answer\" format for active learning training purposes. So instead of just having explanatory code I'd rather go and and try to actively recall (or look up) the answer to a problem I face, which could as simple as loading libraries, to more complex things such as how to fine-tune models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is PyTorch?\n",
    "\n",
    "PyTorch is an open-source deep learning framework developed by Facebook's AI Research lab. It provides a flexible and intuitive platform for building and training neural networks. \n",
    "PyTorch's key features include dynamic computation graphs, which allow for more efficient model building and debugging, and support for GPU acceleration, enabling faster computations. \n",
    "\n",
    "With its extensive library of tools and utilities, PyTorch is widely used for both research and production in machine learning and artificial intelligence projects. These projects include:\n",
    "\n",
    "- **Natural Language Processing (NLP)**: Building models for text classification, sentiment analysis, and machine translation.\n",
    "- **Computer vision**: Implementing image classification, object detection, and image generation tasks.\n",
    "- **Reinforcement learning**: Developing algorithms for game playing and decision-making processes.\n",
    "- **Generative Adversarial Networks (GANs)**: Creating realistic images, videos, and other data generation tasks.\n",
    "- **Time series analysis**: Forecasting and anomaly detection in sequential data.\n",
    "- **Speech recognition**: Building models for converting speech to text and vice versa.\n",
    "- **Robotics**: Developing intelligent control systems for robotic movements and actions.\n",
    "- **Healthcare**: Predictive modeling and medical image analysis for diagnostics and treatment planning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q1: How do you install the base PyTorch libraries using a Jupyter notebook?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q2: How do you import the base PyTorch libraries for later use?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q3: How do you create a tensor in PyTorch? Provide examples of different ways to create tensors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# From a list\n",
    "tensor_from_list = torch.tensor([1, 2, 3, 4])\n",
    "print(tensor_from_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Zeros tensor\n",
    "zeros_tensor = torch.zeros(3, 3)\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Ones tensor\n",
    "ones_tensor = torch.ones(2, 4)\n",
    "print(ones_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2381, 0.0810],\n",
      "        [0.4930, 0.4038],\n",
      "        [0.5550, 0.0527]])\n"
     ]
    }
   ],
   "source": [
    "# Random values\n",
    "random_tensor = torch.rand(3, 2)\n",
    "print(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# From a NumPy array\n",
    "import numpy as np\n",
    "\n",
    "numpy_array = np.array([[1, 2], [3, 4]])\n",
    "tensor_from_numpy = torch.tensor(numpy_array)\n",
    "print(tensor_from_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# With a specific data type\n",
    "float_tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "print(float_tensor)\n",
    "\n",
    "int_tensor = torch.tensor([1, 2, 3], dtype=torch.int32)\n",
    "print(int_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.7516e-01, 1.7530e-42, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "# Uninitialized\n",
    "uninitialized_tensor = torch.empty(2, 3)\n",
    "print(uninitialized_tensor) # it's a tensor whose values are not set and can contain any data that was already present in the allocated memory block, making it useful for performance optimization when the initial values are irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "# Using a range\n",
    "range_tensor = torch.arange(0, 10, step=2)\n",
    "print(range_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "# Using linspace()\n",
    "linspace_tensor = torch.linspace(0, 1, steps=5)\n",
    "print(linspace_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q4: How do you perform basic tensor operations such as addition and multiplication?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "# Create two tensors for the exercise\n",
    "tensor1 = torch.tensor([1, 2, 3])\n",
    "tensor2 = torch.tensor([4, 5, 6])\n",
    "\n",
    "# Element-wise addition\n",
    "result = tensor1 + tensor2\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "# Using torch.add()\n",
    "result = torch.add(tensor1, tensor2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise subtraction\n",
    "result = tensor2 - tensor1\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Using torch.sub()\n",
    "result = torch.sub(tensor2, tensor1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4, 10, 18])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "result = tensor1 * tensor2\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4, 10, 18])\n"
     ]
    }
   ],
   "source": [
    "# Using torch.mul()\n",
    "result = torch.mul(tensor1, tensor2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.0000, 2.5000, 2.0000])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise division\n",
    "result = tensor2 / tensor1\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.0000, 2.5000, 2.0000])\n"
     ]
    }
   ],
   "source": [
    "result = torch.div(tensor2, tensor1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19, 22],\n",
      "        [43, 50]])\n"
     ]
    }
   ],
   "source": [
    "# Examples for matrix operations\n",
    "tensor1 = torch.tensor([[1, 2], [3, 4]])\n",
    "tensor2 = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "# Matrix multiplication\n",
    "result = torch.matmul(tensor1, tensor2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19, 22],\n",
      "        [43, 50]])\n"
     ]
    }
   ],
   "source": [
    "# Using the @ operator\n",
    "result = tensor1 @ tensor2\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 4, 6],\n",
      "        [5, 7, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting (i.e., arithmetic operations on tensors of different shapes)\n",
    "tensor1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "tensor2 = torch.tensor([1, 2, 3])\n",
    "\n",
    "result = tensor1 + tensor2\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q5: How do you slice and index tensors in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "# Indexing a single element\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "element = tensor[0, 1]  # Access the element at row 0, column 1\n",
    "print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Basic slicing\n",
    "slice_tensor = tensor[:2, 1:]  # Slice the first two rows and columns from the second to the end\n",
    "print(slice_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 3],\n",
      "        [7, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Slicing with steps\n",
    "step_slice = tensor[::2, ::2]  # Slice every second element along both dimensions\n",
    "print(step_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 4],\n",
      "        [6, 8]])\n"
     ]
    }
   ],
   "source": [
    "# Select all elements in a dimension with ellipsis\n",
    "tensor = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "ellipsis_slice = tensor[..., 1]  # Select the last element from each sub-array\n",
    "print(ellipsis_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "# Boolean indexing\n",
    "tensor = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "bool_index = tensor[tensor > 3]  # Select elements greater than 3\n",
    "print(bool_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 30, 50])\n"
     ]
    }
   ],
   "source": [
    "# Indexing with a tensor of indices\n",
    "tensor = torch.tensor([10, 20, 30, 40, 50])\n",
    "indices = torch.tensor([0, 2, 4])\n",
    "advanced_index = tensor[indices]  # Select elements at positions 0, 2, and 4\n",
    "print(advanced_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 5],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# Indexing + slicing\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "combined = tensor[1:, :2]  # Slice rows from the second to the end and columns up to the second\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q6: How do you change the shape of a tensor in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Using reshape()\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "reshaped_tensor = tensor.reshape(3, 2)\n",
    "print(reshaped_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Using view()\n",
    "viewed_tensor = tensor.view(3, 2)\n",
    "print(viewed_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Using transpose()\n",
    "transposed_tensor = tensor.transpose(0, 1)\n",
    "print(transposed_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 3],\n",
      "         [5, 7]],\n",
      "\n",
      "        [[2, 4],\n",
      "         [6, 8]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 3D tensor\n",
    "tensor_3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "\n",
    "# Use permute()\n",
    "permuted_tensor = tensor_3d.permute(2, 0, 1)\n",
    "print(permuted_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "# Using flatten()\n",
    "flattened_tensor = tensor.flatten()\n",
    "print(flattened_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q7: How do you concatenate two tensors in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]]) \n",
      "\n",
      "tensor([[ 1,  2,  3,  7,  8,  9],\n",
      "        [ 4,  5,  6, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate along a specified dimension\n",
    "tensor1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "tensor2 = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "\n",
    "# Along the first dimension (rows)\n",
    "concatenated_tensor = torch.cat((tensor1, tensor2), dim=0)\n",
    "print(concatenated_tensor, '\\n')\n",
    "\n",
    "# Along the second dimension (columns)\n",
    "concatenated_tensor = torch.cat((tensor1, tensor2), dim=1)\n",
    "print(concatenated_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]]]) \n",
      "\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 7,  8,  9]],\n",
      "\n",
      "        [[ 4,  5,  6],\n",
      "         [10, 11, 12]]])\n"
     ]
    }
   ],
   "source": [
    "# Stack along a new dimension\n",
    "stacked_tensor = torch.stack((tensor1, tensor2), dim=0)\n",
    "print(stacked_tensor, '\\n')\n",
    "\n",
    "stacked_tensor = torch.stack((tensor1, tensor2), dim=1)\n",
    "print(stacked_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q8: How do you convert a NumPy array to a PyTorch tensor and vice versa?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Create a NumPy array\n",
    "numpy_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Convert the NumPy array to a PyTorch tensor\n",
    "torch_tensor = torch.from_numpy(numpy_array)\n",
    "print(torch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# Create a PyTorch tensor\n",
    "torch_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Convert the PyTorch tensor to a NumPy array\n",
    "numpy_array = torch_tensor.numpy()\n",
    "print(numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) \n",
      "\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# Avoiding memory sharing by creating a copy\n",
    "torch_tensor_copy = torch.from_numpy(numpy_array.copy())\n",
    "numpy_array_copy = torch_tensor.numpy().copy()\n",
    "\n",
    "print(torch_tensor_copy, '\\n') \n",
    "print(numpy_array_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q9: How do you get the size and shape of a tensor in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Get the size of a tensor\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "size = tensor.size()\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Get the shape of the tensor\n",
    "shape = tensor.shape\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Get number of dimensions\n",
    "num_dimensions = tensor.ndimension()\n",
    "print(num_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 2, Columns: 3\n"
     ]
    }
   ],
   "source": [
    "# Get size of a specific dimension\n",
    "rows = tensor.size(0)\n",
    "cols = tensor.size(1)\n",
    "print(f\"Rows: {rows}, Columns: {cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q10: How do you use advanced indexing techniques in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "# Boolean indexing\n",
    "tensor = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "mask = tensor > 3\n",
    "selected_elements = tensor[mask]\n",
    "print(selected_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 30, 50])\n"
     ]
    }
   ],
   "source": [
    "# Indexing with another tensor\n",
    "tensor = torch.tensor([10, 20, 30, 40, 50])\n",
    "\n",
    "indices = torch.tensor([0, 2, 4])\n",
    "selected_elements = tensor[indices]\n",
    "print(selected_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Indexing with a list of indices\n",
    "tensor = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "selected_rows = tensor[[0, 2]]\n",
    "print(selected_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "# Use the mask with integer indexing\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "mask = tensor > 4\n",
    "\n",
    "selected_elements = tensor[mask]\n",
    "print(selected_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Ellipsis indexing\n",
    "tensor = torch.randn(3, 4, 5)\n",
    "\n",
    "selected_elements = tensor[..., 1]\n",
    "print(selected_elements.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [4, 3],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Using torch.gather()\n",
    "tensor = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "indices = torch.tensor([[0, 0], [1, 0], [0, 1]])\n",
    "\n",
    "gathered_tensor = torch.gather(tensor, 1, indices)\n",
    "print(gathered_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q11: How do you check if a GPU is available in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "GPU Name: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"GPU Name: {gpu_name}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q12: How do you move tensors to GPU and perform operations on them?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "tensor_cpu = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "# Move the tensor to GPU\n",
    "tensor_gpu = tensor_cpu.to(device)\n",
    "\n",
    "# Alternatively, you can use .cuda() if device is explicitly set to \"cuda\"\n",
    "# tensor_gpu = tensor_cpu.cuda()\n",
    "\n",
    "print(tensor_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Perform operations on GPU\n",
    "another_tensor_gpu = torch.tensor([4.0, 5.0, 6.0]).to(device)\n",
    "\n",
    "result = tensor_gpu + another_tensor_gpu\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move an entire model to GPU\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(3, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2044, -0.3446,  1.1305], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Move the model to GPU\n",
    "model.to(device)\n",
    "\n",
    "# Create input tensor and move to GPU\n",
    "input_tensor = torch.tensor([1.0, 2.0, 3.0]).to(device)\n",
    "\n",
    "# Perform a forward pass\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q13: How do you measure the time taken for tensor operations on GPU versus CPU?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for CPU operation: 3.9019978046417236 seconds\n"
     ]
    }
   ],
   "source": [
    "# Time for CPU operations\n",
    "import time\n",
    "\n",
    "tensor_cpu = torch.randn(10000, 10000)\n",
    "\n",
    "# Measure the time\n",
    "start_time = time.time()\n",
    "result_cpu = tensor_cpu @ tensor_cpu  # Matrix multiplication\n",
    "end_time = time.time()\n",
    "\n",
    "cpu_time = end_time - start_time\n",
    "print(f\"Time for CPU operation: {cpu_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for GPU operation: 0.8348789215087891 seconds\n"
     ]
    }
   ],
   "source": [
    "# Time for GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    tensor_gpu = tensor_cpu.to(device)\n",
    "\n",
    "    # Warm up the GPU\n",
    "    _ = tensor_gpu @ tensor_gpu\n",
    "\n",
    "    # Measure the time\n",
    "    start_time = time.time()\n",
    "    result_gpu = tensor_gpu @ tensor_gpu  # Matrix multiplication\n",
    "    torch.cuda.synchronize()  # Wait for GPU operations to complete\n",
    "    end_time = time.time()\n",
    "\n",
    "    gpu_time = end_time - start_time\n",
    "    print(f\"Time for GPU operation: {gpu_time} seconds\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time for CPU operation over 10 runs: 4.267933060001814 seconds\n"
     ]
    }
   ],
   "source": [
    "# Alternative: use the timeit module to take the average from multiple operations\n",
    "import timeit\n",
    "\n",
    "tensor_cpu = torch.randn(10000, 10000)\n",
    "\n",
    "# Time for a CPU operation\n",
    "cpu_time = timeit.timeit('tensor_cpu @ tensor_cpu', globals=globals(), number=10)\n",
    "print(f\"Average time for CPU operation over 10 runs: {cpu_time / 10} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time for GPU operation over 10 runs: 0.4593087299988838 seconds\n"
     ]
    }
   ],
   "source": [
    "# timeit on GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    tensor_gpu = tensor_cpu.to(device)\n",
    "\n",
    "    # Warm up the GPU\n",
    "    _ = tensor_gpu @ tensor_gpu\n",
    "\n",
    "    # Measure the time\n",
    "    def gpu_operation():\n",
    "        result_gpu = tensor_gpu @ tensor_gpu\n",
    "        torch.cuda.synchronize()  # Wait for GPU operations to complete\n",
    "\n",
    "    gpu_time = timeit.timeit(gpu_operation, number=10)\n",
    "    print(f\"Average time for GPU operation over 10 runs: {gpu_time / 10} seconds\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q14: How do you handle tensors when working with multiple GPUs?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 1\n",
      "Multiple GPUs are not available.\n"
     ]
    }
   ],
   "source": [
    "# Check the number of available GPUs\n",
    "n_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of available GPUs: {n_gpus}\")\n",
    "\n",
    "# List available GPUs\n",
    "if n_gpus > 1:\n",
    "    for i in range(n_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"Multiple GPUs are not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5793,  1.2301,  0.3336, -0.0730,  0.4936, -0.0848,  0.4817, -0.2437,\n",
      "         -0.9768, -0.0174],\n",
      "        [-1.1025, -0.7745,  0.1287, -0.5809, -0.5398, -0.9629, -0.4118, -0.7461,\n",
      "          0.1665, -0.1868],\n",
      "        [-0.1357,  0.5453, -0.2181,  1.6246, -0.1711,  1.6612,  0.1437, -0.3999,\n",
      "         -0.3275,  0.7510],\n",
      "        [-0.2530,  0.1424,  0.6478,  0.0620,  0.4956,  0.3044,  0.2441,  0.3048,\n",
      "          0.1568,  0.2696],\n",
      "        [-0.5817,  0.6161, -0.8001,  0.7301,  0.3400,  0.7400,  0.2450, -0.2854,\n",
      "         -0.1619,  0.8682],\n",
      "        [ 0.0060,  0.3469,  0.6073,  0.0050,  0.9235,  0.3002,  0.7779, -0.0766,\n",
      "          0.1940,  0.3077],\n",
      "        [-0.4639, -0.1702,  0.0768,  0.0903, -0.2852, -0.2345, -0.2375, -0.9020,\n",
      "          0.1045, -0.3338],\n",
      "        [-0.7160, -0.4117,  0.3285, -0.2942, -0.2763, -0.2346, -0.3866, -0.3820,\n",
      "          0.8440, -0.7600],\n",
      "        [ 0.0342,  0.8916,  0.2006,  1.3373,  0.6596,  1.5486,  0.0214,  0.6591,\n",
      "         -0.2724,  0.8520],\n",
      "        [-0.4273, -0.5155,  0.2994, -0.0915, -0.1060,  0.0769,  0.2316, -0.3325,\n",
      "          0.6385,  0.0176],\n",
      "        [ 0.5314,  0.1549, -0.5921,  0.6759,  0.4174,  0.7634, -0.2918,  0.0579,\n",
      "          0.1922,  0.3317],\n",
      "        [ 0.3546,  0.1088,  1.2990, -0.0451,  0.6056,  0.1399, -0.2891,  0.9037,\n",
      "          0.3933, -0.6088],\n",
      "        [ 0.5831, -0.2978,  0.8162, -0.0037,  0.4614, -0.0231, -0.1605,  0.2982,\n",
      "         -0.0662, -0.1714],\n",
      "        [-0.1938, -0.2334,  1.4802,  0.9146,  0.1697,  0.4854, -0.4325, -0.7615,\n",
      "          0.8836, -1.6244],\n",
      "        [-0.0322,  1.5802,  0.5332, -0.6360,  0.3267,  0.0482,  0.5835,  0.5022,\n",
      "         -0.2176,  0.1436],\n",
      "        [-0.3209,  0.1869,  0.4917,  0.3993,  0.3117,  0.6235,  0.0170,  0.7157,\n",
      "          0.2707,  0.2079],\n",
      "        [-0.6509, -0.5077,  0.0736,  0.9726,  0.3193,  0.6114, -0.5756, -0.1033,\n",
      "         -0.0425,  0.1507],\n",
      "        [-0.1972, -0.0968,  0.7449,  0.6187,  0.3310,  0.3744, -0.3779,  0.0187,\n",
      "         -0.0594, -0.3654],\n",
      "        [-1.1081,  0.0743,  0.5606, -0.8407, -0.5344, -0.8291,  0.6376, -1.1472,\n",
      "          0.7425, -0.7025],\n",
      "        [ 0.5355, -0.2817, -0.1054,  0.1372,  0.3398,  0.0196, -0.8076, -0.3174,\n",
      "         -0.3354,  0.0052],\n",
      "        [-0.4868, -1.0822, -0.6834, -1.2965, -0.8802, -1.2677, -1.2855, -0.4651,\n",
      "          0.6193, -0.7124],\n",
      "        [-0.0277, -1.2166,  1.0382, -0.0788, -0.3046, -0.5963,  0.0801, -1.3060,\n",
      "          0.0823, -0.9426],\n",
      "        [ 0.0633, -0.0696,  1.2855,  0.4876,  1.1349,  0.7596,  0.1553,  0.8940,\n",
      "          0.4285,  0.0129],\n",
      "        [-1.2459,  0.3183, -1.1420, -0.2802, -0.3957, -0.4157,  0.4053, -1.0721,\n",
      "         -0.2944,  0.6584],\n",
      "        [-0.4151,  0.5464, -0.1063,  0.2502,  0.8543,  0.4391,  0.1356,  1.5723,\n",
      "         -0.7175,  1.5552],\n",
      "        [-0.7685, -0.2139,  1.2085,  0.3204, -0.0538,  0.3176,  0.5973, -1.0190,\n",
      "          0.7182, -0.7126],\n",
      "        [-0.7366, -0.0887, -0.9702, -0.2570, -0.2703, -0.1739, -1.3187, -0.0043,\n",
      "          0.6889, -0.1854],\n",
      "        [-0.2633,  0.6310,  0.4175, -0.6904, -0.0202, -0.2686, -0.2199,  0.2626,\n",
      "          0.9247, -0.8309],\n",
      "        [-0.7507, -0.9678, -0.1526,  1.3060,  0.0402,  0.4831, -0.1085, -1.0433,\n",
      "         -0.2055,  0.2382],\n",
      "        [ 0.0640,  0.0370,  0.7190, -0.1468,  0.3508, -0.0998, -0.0270, -0.3332,\n",
      "          0.6427, -0.7565],\n",
      "        [-0.0274, -1.4426,  1.1893, -0.7881,  0.4132, -1.0869, -0.7269,  0.5560,\n",
      "         -0.5848, -0.2690],\n",
      "        [-0.0855,  0.2680,  0.2378,  0.8191,  0.9062,  0.9238, -1.1633,  0.9816,\n",
      "          0.4977, -0.1814],\n",
      "        [-0.3948,  0.7339,  0.5572,  0.5797,  0.3824,  0.7386, -0.0515,  0.0140,\n",
      "          0.6710, -0.4241],\n",
      "        [-0.3220,  0.8639,  0.3636,  0.4024,  0.0115,  0.6671,  0.3612, -0.5348,\n",
      "          0.7821, -0.3130],\n",
      "        [ 0.0879,  0.0299,  0.1785,  1.1133,  0.4447,  1.2811, -0.0482,  0.2746,\n",
      "          0.5308,  0.2619],\n",
      "        [-0.4815, -0.3974, -0.4644,  0.1569, -0.0463,  0.1586, -1.0692,  0.0851,\n",
      "          0.5778, -0.0814],\n",
      "        [-0.4589, -1.0116,  0.4886, -0.2105,  0.8212, -0.6953, -0.0669, -0.3156,\n",
      "         -0.7360,  0.3215],\n",
      "        [-0.2380,  0.6500,  0.0289,  0.4601,  0.4108,  0.4962, -0.8813,  0.6112,\n",
      "         -0.5016,  0.2139],\n",
      "        [ 0.1617, -0.3496,  0.9433, -0.3624,  0.4916,  0.0555, -0.3725,  0.2770,\n",
      "          0.9256, -0.7907],\n",
      "        [ 0.7632, -0.6948,  0.6623, -0.3697,  0.4640, -0.2917,  0.1433,  0.4437,\n",
      "         -0.6986,  0.3458],\n",
      "        [ 0.3038, -0.1455,  1.1083,  0.3541,  0.6014,  0.3837, -0.1463,  0.1091,\n",
      "          0.2729, -0.5129],\n",
      "        [-1.2923,  1.5399, -0.5009,  0.2158, -0.4874,  0.6762,  1.1784, -1.0372,\n",
      "          0.7471,  0.4017],\n",
      "        [ 0.8844, -0.7750,  1.6598,  0.4076,  1.3451,  0.3722, -0.9292,  1.2716,\n",
      "          0.0553, -0.5980],\n",
      "        [ 0.3250, -0.1469,  0.0117,  0.9297, -0.0299,  0.8864, -0.1218, -0.2947,\n",
      "          0.0297,  0.2243],\n",
      "        [ 0.0711, -0.1187, -0.2465,  0.3623,  0.5336,  0.4854,  0.6868, -0.0368,\n",
      "         -0.4026,  0.9748],\n",
      "        [-0.2255, -0.7139,  0.2092,  0.0200, -0.3697, -0.0743,  0.9922, -0.6094,\n",
      "         -0.1628,  0.6127],\n",
      "        [-0.4132,  0.7383,  0.6211,  0.8051,  0.7700,  1.0827, -0.6669,  0.2328,\n",
      "          1.2793, -0.6786],\n",
      "        [-1.0333, -0.1180, -0.3025, -0.1319, -0.7319, -0.1834,  0.3804, -0.4605,\n",
      "         -0.1100,  0.5938],\n",
      "        [-0.3796,  0.5946, -1.3694, -0.8036,  0.1766, -0.6641, -0.4873, -0.3206,\n",
      "         -0.1307,  0.5754],\n",
      "        [-0.0122, -1.3808,  0.2069, -0.2850,  0.5987, -0.7094, -0.2784,  0.3893,\n",
      "         -0.5903,  0.6120],\n",
      "        [-0.9357,  0.3218, -0.2622,  0.8501,  0.7724,  0.7460, -1.0484,  0.1683,\n",
      "          0.3319, -0.2428],\n",
      "        [-0.3123,  0.2261,  0.7590,  0.2928,  1.1216,  0.3990,  0.3134, -0.1582,\n",
      "          0.8932, -0.1700],\n",
      "        [-0.2980,  0.3192, -0.2324, -0.7684,  0.2867, -0.5445, -0.1878,  0.2927,\n",
      "          0.0141,  0.3020],\n",
      "        [-0.9496,  0.1293,  0.6601,  0.1987, -0.6875,  0.2898,  0.4395, -0.1847,\n",
      "          0.5145, -0.2048],\n",
      "        [ 0.0710,  1.3516, -0.2413,  0.1163, -0.2001,  0.5143, -0.7461,  0.0456,\n",
      "          0.5862, -0.6183],\n",
      "        [-0.1750,  0.9822,  0.4444,  0.0522, -0.1422,  0.4167,  1.3662, -0.1772,\n",
      "          0.0509,  0.2798],\n",
      "        [ 0.2158,  0.1546,  0.1331,  0.3007,  0.7799,  0.2151, -0.7309,  0.3748,\n",
      "         -0.6557,  0.2159],\n",
      "        [-0.6514,  0.2430, -0.0234,  0.2317,  0.3142,  0.3205,  0.8072, -0.2451,\n",
      "          0.0718,  0.6199],\n",
      "        [-0.2997, -0.3925, -0.6829,  1.1273,  0.0740,  1.0050, -0.7147, -0.4116,\n",
      "          0.7957,  0.3234],\n",
      "        [-0.4416,  1.4291,  0.6853, -0.2701, -0.1123,  0.4255, -0.1010,  0.1144,\n",
      "          1.1571, -1.2574],\n",
      "        [ 0.0275,  0.0057,  0.2529,  1.4160,  0.2159,  1.4202, -0.8557,  0.3882,\n",
      "          0.3317, -0.1712],\n",
      "        [-0.1490,  0.6235,  0.4488, -0.5791,  0.3685,  0.0160, -0.3626,  1.2654,\n",
      "          0.4123,  0.0813],\n",
      "        [-0.0166,  0.3063,  0.9729, -0.2173, -0.3109, -0.0344, -0.0725, -0.2807,\n",
      "          0.2016, -1.0091],\n",
      "        [-0.6178,  0.4860, -0.0780, -0.1432, -0.3302, -0.2831,  0.6712, -0.7698,\n",
      "         -0.3029,  0.2535]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Had multiple GPUs been available, one could work with torch.nn.DataParallel. e.g.,\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = SimpleModel()\n",
    "\n",
    "if n_gpus > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model = model.to('cuda')\n",
    "\n",
    "input_tensor = torch.randn(64, 10).to('cuda')\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q15: How do you enable automatic differentiation in PyTorch and compute gradients?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with requires_grad=True to enable automatic differentiation\n",
    "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Define a simple operation\n",
    "y = x[0] * x[1] + x[1] ** 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 8.])\n"
     ]
    }
   ],
   "source": [
    "# Compute gradients\n",
    "y.backward()\n",
    "\n",
    "# Print gradients\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.)\n"
     ]
    }
   ],
   "source": [
    "# Disable gradient calculation (when no longer needed)\n",
    "with torch.no_grad():\n",
    "    z = x[0] * x[1] + x[1] ** 2\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x1e44c3c9350>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, using torch.set_grad_enabled(False)\n",
    "torch.set_grad_enabled(False)\n",
    "z = x[0] * x[1] + x[1] ** 2\n",
    "print(z)\n",
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q16: How do you stop PyTorch from tracking history on tensors?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.)\n"
     ]
    }
   ],
   "source": [
    "# Use torch.no_grad()\n",
    "# Create a tensor with requires_grad=True\n",
    "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# Perform operations without tracking history\n",
    "with torch.no_grad():\n",
    "    y = x[0] * x[1] + x[1] ** 2\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Verify that no gradient is tracked\n",
    "print(y.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.)\n"
     ]
    }
   ],
   "source": [
    "# Can also use .detach()\n",
    "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# Detach the tensor from the computation graph\n",
    "x_detached = x.detach()\n",
    "\n",
    "# Perform operations on the detached tensor\n",
    "y = x_detached[0] * x_detached[1] + x_detached[1] ** 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Verify that no gradient is tracked\n",
    "print(x_detached.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q17: How do you manually zero the gradients in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3890], grad_fn=<ViewBackward0>)\n",
      "tensor(0.3583, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Use optimizer.zero_grad()\n",
    "import torch.optim as optim\n",
    "\n",
    "model = nn.Linear(10, 1)\n",
    "\n",
    "# Define a loss function and an optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Dummy input and target tensors\n",
    "input_tensor = torch.randn(10)\n",
    "target_tensor = torch.randn(1)\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_tensor)\n",
    "loss = criterion(output, target_tensor)\n",
    "\n",
    "print(output)\n",
    "print(loss)\n",
    "\n",
    "# Backward pass\n",
    "optimizer.zero_grad()  # Reset gradients\n",
    "loss.backward()        # Compute gradients\n",
    "optimizer.step()       # Update model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 8.])\n"
     ]
    }
   ],
   "source": [
    "# You can also manually zero gradients for specific tensors\n",
    "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "\n",
    "y = x[0] * x[1] + x[1] ** 2\n",
    "\n",
    "y.backward()\n",
    "\n",
    "# Print gradients before zeroing\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Manually zero the gradients\n",
    "x.grad.zero_()\n",
    "\n",
    "# Verify gradients are zeroed\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q18: How do you use the `backward()` method for computing gradients?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# First, set up tensors and a simple operation\n",
    "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "\n",
    "y = x[0] * x[1] + x[1] ** 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 8.])\n"
     ]
    }
   ],
   "source": [
    "# Compute and print gradients\n",
    "y.backward()\n",
    "\n",
    "print(x.grad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7., 14.])\n"
     ]
    }
   ],
   "source": [
    "# You can also use non-scalar outputs\n",
    "z = x ** 2\n",
    "\n",
    "# Compute gradients with a gradient argument\n",
    "z.backward(torch.tensor([1.0, 1.0]))\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q19: How do you define a simple neural network using `nn.Module` in PyTorch?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries - which have already been imported in previous cells\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network class with a forward method in it\n",
    "class SimpleNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNetwork, self).__init__()\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(10, 50)  # Input layer to hidden layer\n",
    "        self.fc2 = nn.Linear(50, 20)  # Hidden layer to hidden layer\n",
    "        self.fc3 = nn.Linear(20, 1)   # Hidden layer to output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define forward pass\n",
    "        x = torch.relu(self.fc1(x))  # Apply ReLU activation function\n",
    "        x = torch.relu(self.fc2(x))  # Apply ReLU activation function\n",
    "        x = self.fc3(x)              # Output layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up the model\n",
    "model = SimpleNeuralNetwork().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss().to(device)                 # Mean Squared Error Loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Stochastic Gradient Descent\n",
    "\n",
    "# Dummy input and target tensors for demonstration\n",
    "inputs = torch.randn(5, 10).to(device)   # 5 samples, each with 10 features\n",
    "targets = torch.randn(5, 1).to(device)   # 5 samples, each with 1 target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.1220\n",
      "Epoch [200/1000], Loss: 0.0190\n",
      "Epoch [300/1000], Loss: 0.0020\n",
      "Epoch [400/1000], Loss: 0.0003\n",
      "Epoch [500/1000], Loss: 0.0001\n",
      "Epoch [600/1000], Loss: 0.0000\n",
      "Epoch [700/1000], Loss: 0.0000\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Epoch [1000/1000], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q20: How do you initialize the weights and biases of a neural network?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the torch.nn.init module\n",
    "import torch.nn.init as init\n",
    "\n",
    "class SimpleNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 50)\n",
    "        self.fc2 = nn.Linear(50, 20)\n",
    "        self.fc3 = nn.Linear(20, 1)\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        # Apply Xavier initialization to weights and zero initialization to biases\n",
    "        init.xavier_uniform_(self.fc1.weight)\n",
    "        init.zeros_(self.fc1.bias)\n",
    "        init.xavier_uniform_(self.fc2.weight)\n",
    "        init.zeros_(self.fc2.bias)\n",
    "        init.xavier_uniform_(self.fc3.weight)\n",
    "        init.zeros_(self.fc3.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNeuralNetwork(\n",
      "  (fc1): Linear(in_features=10, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: use custom initialization functions\n",
    "def custom_weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # Apply custom initialization\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.01)\n",
    "        nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "class SimpleNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 50)\n",
    "        self.fc2 = nn.Linear(50, 20)\n",
    "        self.fc3 = nn.Linear(20, 1)\n",
    "        self.apply(custom_weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNeuralNetwork(\n",
      "  (fc1): Linear(in_features=10, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another option: Use built-in initializations in layers\n",
    "class SimpleNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 50)\n",
    "        self.fc2 = nn.Linear(50, 20)\n",
    "        self.fc3 = nn.Linear(20, 1)\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        # Apply He initialization to weights and zero initialization to biases\n",
    "        init.kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n",
    "        init.zeros_(self.fc1.bias)\n",
    "        init.kaiming_uniform_(self.fc2.weight, nonlinearity='relu')\n",
    "        init.zeros_(self.fc2.bias)\n",
    "        init.kaiming_uniform_(self.fc3.weight, nonlinearity='relu')\n",
    "        init.zeros_(self.fc3.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNeuralNetwork(\n",
      "  (fc1): Linear(in_features=10, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q21: How do you add multiple layers to a neural network?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use nn.Sequential\n",
    "class SimpleSequentialNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleSequentialNN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(10, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleSequentialNN(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleSequentialNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, define each layer explicitly\n",
    "class SimpleExplicitNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleExplicitNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 50)\n",
    "        self.fc2 = nn.Linear(50, 20)\n",
    "        self.fc3 = nn.Linear(20, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleExplicitNN(\n",
      "  (fc1): Linear(in_features=10, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleExplicitNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, add multiple layers w/ different architectures\n",
    "class ComplexNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # Assuming input images are 28x28\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)  # Flatten the tensor\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComplexNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ComplexNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q22: How do you define a loss function and an optimizer for your neural network?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q23: How do you use different types of optimizers in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q24: How do you adjust the learning rate during training?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q25: How do you create a training loop to train your neural network in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q26: How do you evaluate your model's performance and make predictions on new data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q27: How do you calculate the accuracy of your model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q28: How do you handle model evaluation for regression tasks?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q29: How do you handle model evaluation for classification tasks?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q30: How do you use confusion matrices to evaluate model performance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q31: How do you save and load a PyTorch model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q32: How do you save and load model checkpoints during training?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q33: How do you use PyTorch's DataLoader to load a dataset in batches?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q34: How do you implement a custom dataset in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q35: How do you apply data transformations using `torchvision.transforms`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q36: How do you handle data augmentation in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q37: How do you create a tensor of shape (2, 3) filled with zeros and then with ones?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q38: How do you train a neural network to predict the output of a simple linear function?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q39: How do you experiment with different optimizers and learning rates to see their effect on training?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q40: How do you visualize the training loss and accuracy over epochs in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q41: How do you implement dropout regularization in a neural network using PyTorch?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
