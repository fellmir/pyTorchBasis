{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression in PyTorch\n",
    "\n",
    "Welcome to the `02_linear_regression` notebook. This is part of a portfolio designed to showcase foundational concepts and techniques in PyTorch, with this one focusing on linear regression — a fundamental algorithm in machine learning used for predicting a continuous target variable based on one or more input features.\n",
    "\n",
    "In this notebook, I cover essential topics including generating synthetic data, defining and training a linear regression model, and evaluating its performance. I'll also explore optimizations and best practices to improve model accuracy and efficiency. \n",
    "\n",
    "Through various exercises, this notebook demonstrates practical applications of linear regression in PyTorch, providing a solid foundation for more advanced projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Understanding linear regression](#understanding-linear-regression)\n",
    "2. [Setting up the environment](#setting-up-the-environment)\n",
    "3. [Generating synthetic data](#generating-synthetic-data)\n",
    "4. [Defining the linear regression model](#defining-the-linear-regression-model)\n",
    "5. [Loss function and optimizer](#loss-function-and-optimizer)\n",
    "6. [Training the linear regression model](#training-the-linear-regression-model)\n",
    "7. [Evaluating the model](#evaluating-the-model)\n",
    "8. [Saving and loading the model](#saving-and-loading-the-model)\n",
    "9. [Optimizations](#optimizations)\n",
    "10. [Conclusion](#conclusion)\n",
    "11. [Further exercises](#further-exercises)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding linear regression\n",
    "\n",
    "Linear regression is a fundamental statistical method used in machine learning and data analysis to model the relationship between one or more input variables (features) and a continuous output variable (target). The primary objective of linear regression is to find the best-fitting straight line (or hyperplane in higher dimensions) that can predict the target variable from the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key concepts\n",
    "\n",
    "#### 1. Simple vs. multiple linear regression\n",
    "- **Simple linear regression**: Involves a single input variable and aims to model the relationship between this variable and the target variable. The goal is to find a straight line that best describes this relationship.\n",
    "- **Multiple linear regression**: Involves two or more input variables. The model tries to fit a hyperplane in a multidimensional space to predict the target variable.\n",
    "\n",
    "#### 2. The best-fit line\n",
    "The best-fit line (or hyperplane) is the one that minimizes the difference between the actual target values and the predicted values. This difference is known as the residuals. The smaller the residuals, the better the model fits the data.\n",
    "\n",
    "#### 3. Model parameters\n",
    "Linear regression models have coefficients (weights) and an intercept (bias). The coefficients represent the relationship between each input feature and the target variable. The intercept is the value of the target variable when all input features are zero.\n",
    "\n",
    "#### 4. Assumptions of linear regression\n",
    "For linear regression to provide reliable results, several assumptions must be met:\n",
    "- **Linearity**: The relationship between the input features and the target variable should be linear.\n",
    "- **Independence**: The residuals (errors) should be independent of each other.\n",
    "- **Homoscedasticity**: The residuals should have constant variance across all levels of the input features.\n",
    "- **Normality**: The residuals should be normally distributed.\n",
    "\n",
    "#### 5. Model evaluation\n",
    "To evaluate the performance of a linear regression model, several metrics are commonly used:\n",
    "- **Mean Squared Error (MSE)**: Measures the average squared difference between actual and predicted values. Lower values indicate a better fit.\n",
    "- **R-squared (R²)**: Represents the proportion of variance in the target variable that can be explained by the input features. Values range from 0 to 1, with higher values indicating a better fit.\n",
    "\n",
    "#### 6. Overfitting and underfitting\n",
    "- **Overfitting**: Occurs when the model learns the noise in the training data, leading to poor generalization to new data. This can happen if the model is too complex.\n",
    "- **Underfitting**: Occurs when the model is too simple to capture the underlying pattern in the data, leading to poor performance on both training and new data.\n",
    "\n",
    "#### 7. Regularization\n",
    "Regularization techniques are used to prevent overfitting by adding a penalty to the model's complexity. Common regularization methods include:\n",
    "- **Ridge regression (L2 Regularization)**: Adds a penalty proportional to the square of the coefficients.\n",
    "- **Lasso regression (L1 Regularization)**: Adds a penalty proportional to the absolute value of the coefficients, which can lead to sparse models with some coefficients being zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications\n",
    "\n",
    "#### Economics and finance\n",
    "- **Stock price prediction**: Estimating future stock prices based on historical data and market indicators.\n",
    "- **Risk management**: Assessing the relationship between risk factors and asset returns.\n",
    "- **Economic forecasting**: Predicting economic indicators such as GDP growth, inflation rates, and unemployment rates.\n",
    "- **Credit scoring**: Evaluating the likelihood of a borrower defaulting on a loan based on their financial history.\n",
    "\n",
    "#### Healthcare\n",
    "- **Disease progression**: Modeling the progression of diseases over time based on patient data.\n",
    "- **Healthcare costs**: Predicting healthcare costs for individuals or populations based on demographic and medical history data.\n",
    "- **Medical research**: Identifying relationships between various factors (e.g., lifestyle, genetics) and health outcomes.\n",
    "- **Patient outcomes**: Forecasting patient recovery times or survival rates based on treatment variables.\n",
    "\n",
    "#### Marketing and sales\n",
    "- **Sales forecasting**: Estimating future sales based on historical sales data, seasonality, and market trends.\n",
    "- **Customer lifetime value**: Predicting the long-term value of customers based on their purchasing behavior.\n",
    "- **Advertising effectiveness**: Assessing the impact of advertising campaigns on sales or brand awareness.\n",
    "- **Market analysis**: Identifying trends and relationships in consumer behavior and market data.\n",
    "\n",
    "#### Environmental science\n",
    "- **Climate modeling**: Analyzing the relationship between greenhouse gas emissions and global temperatures.\n",
    "- **Pollution levels**: Predicting pollution levels based on industrial activities, traffic patterns, and weather conditions.\n",
    "- **Water quality**: Estimating water quality parameters based on land use, agricultural practices, and rainfall data.\n",
    "- **Renewable energy forecasting**: Predicting the output of renewable energy sources like solar and wind based on weather conditions.\n",
    "\n",
    "#### Real estate\n",
    "- **Property valuation**: Estimating the value of properties based on features such as location, size, and amenities.\n",
    "- **Rental price prediction**: Forecasting rental prices based on market conditions and property characteristics.\n",
    "- **Market trends**: Analyzing trends in the real estate market to guide investment decisions.\n",
    "\n",
    "#### Social sciences\n",
    "- **Sociological research**: Examining relationships between social factors (e.g., education, income) and various outcomes (e.g., crime rates, health).\n",
    "- **Education analysis**: Predicting student performance based on socioeconomic background, school resources, and attendance.\n",
    "\n",
    "#### Engineering and manufacturing\n",
    "- **Quality control**: Monitoring and predicting product quality based on production parameters.\n",
    "- **Process optimization**: Modeling relationships between input variables and output quality to optimize manufacturing processes.\n",
    "- **Failure prediction**: Estimating the likelihood of equipment failure based on usage data and maintenance history.\n",
    "\n",
    "#### Sports and performance analysis\n",
    "- **Player performance**: Predicting athlete performance based on historical performance data and training metrics.\n",
    "- **Game outcome prediction**: Estimating the outcomes of sports events based on team statistics and player performance.\n",
    "\n",
    "#### Agriculture\n",
    "- **Crop yield prediction**: Forecasting crop yields based on factors such as weather conditions, soil quality, and farming practices.\n",
    "- **Livestock health**: Modeling the health and productivity of livestock based on feeding practices and environmental conditions.\n",
    "\n",
    "#### Transportation and logistics\n",
    "- **Demand forecasting**: Predicting transportation demand for public transit systems or ride-sharing services.\n",
    "- **Logistics optimization**: Estimating delivery times and optimizing routes based on traffic patterns and order volumes.\n",
    "\n",
    "#### Insurance\n",
    "- **Premium calculation**: Determining insurance premiums based on risk factors such as age, health status, and driving history.\n",
    "- **Claim prediction**: Estimating the likelihood of insurance claims based on customer data and historical claim records.\n",
    "\n",
    "#### Technology and internet\n",
    "- **User behavior analysis**: Predicting user engagement and retention based on interaction data from websites and apps.\n",
    "- **Recommendation systems**: Modeling user preferences to provide personalized content or product recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maths\n",
    "\n",
    "Linear regression aims to model the relationship between a dependent variable $ y $ and one or more independent variables $ x_1, x_2, \\ldots, x_n $. The goal is to find the best-fitting linear equation that predicts the value of $ y $ from the input variables.\n",
    "\n",
    "#### Simple linear regression\n",
    "For simplicity, let's start with simple linear regression, where there is only one independent variable $ x $.\n",
    "\n",
    "##### 1. The linear model\n",
    "The model assumes a linear relationship between the independent variable $ x $ and the dependent variable $ y $:\n",
    "$$ y = \\beta_0 + \\beta_1 x + \\epsilon $$\n",
    "- $ \\beta_0 $ is the intercept (the value of $ y $ when $ x = 0 $).\n",
    "- $ \\beta_1 $ is the slope (the change in $ y $ for a one-unit change in $ x $).\n",
    "- $ \\epsilon $ is the error term, representing the deviation of the observed values from the true line.\n",
    "\n",
    "##### 2. The objective\n",
    "The objective of linear regression is to estimate the coefficients $ \\beta_0 $ and $ \\beta_1 $ such that the sum of the squared differences between the observed values $ y_i $ and the predicted values $ \\hat{y_i} $ is minimized. This method is known as **Ordinary Least Squares (OLS)**.\n",
    "\n",
    "##### 3. The cost function\n",
    "The cost function, also known as the **mean squared error (MSE)**, is defined as:\n",
    "$$ J(\\beta_0, \\beta_1) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2 $$\n",
    "where:\n",
    "$$ \\hat{y_i} = \\beta_0 + \\beta_1 x_i $$\n",
    "- $ n $ is the number of data points.\n",
    "- $ y_i $ are the actual values.\n",
    "- $ \\hat{y_i} $ are the predicted values.\n",
    "\n",
    "##### 4. Minimizing the cost function\n",
    "To find the values of $ \\beta_0 $ and $ \\beta_1 $ that minimize the cost function, we take the partial derivatives of $ J(\\beta_0, \\beta_1) $ with respect to $ \\beta_0 $ and $ \\beta_1 $, set them to zero, and solve for $ \\beta_0 $ and $ \\beta_1 $.\n",
    "\n",
    "The partial derivatives are:\n",
    "$$ \\frac{\\partial J}{\\partial \\beta_0} = -\\frac{2}{n} \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i) = 0 $$\n",
    "$$ \\frac{\\partial J}{\\partial \\beta_1} = -\\frac{2}{n} \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i) x_i = 0 $$\n",
    "\n",
    "Solving these equations simultaneously gives the estimates:\n",
    "$$ \\beta_1 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} $$\n",
    "$$ \\beta_0 = \\bar{y} - \\beta_1 \\bar{x} $$\n",
    "where:\n",
    "- $ \\bar{x} $ is the mean of the $ x $ values.\n",
    "- $ \\bar{y} $ is the mean of the $ y $ values.\n",
    "\n",
    "#### Multiple linear regression\n",
    "When there are multiple independent variables, the model extends to:\n",
    "$$ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n + \\epsilon $$\n",
    "\n",
    "##### 1. The vector form\n",
    "This can be written in vector form for convenience:\n",
    "$$ \\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon} $$\n",
    "where:\n",
    "- $ \\mathbf{y} $ is the vector of observed values.\n",
    "- $ \\mathbf{X} $ is the matrix of input features, including a column of ones for the intercept.\n",
    "- $ \\boldsymbol{\\beta} $ is the vector of coefficients.\n",
    "- $ \\boldsymbol{\\epsilon} $ is the vector of error terms.\n",
    "\n",
    "##### 2. The cost function\n",
    "The cost function in multiple linear regression is similarly:\n",
    "$$ J(\\boldsymbol{\\beta}) = \\frac{1}{n} (\\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta})^T (\\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta}) $$\n",
    "\n",
    "##### 3. Solving for the coefficients\n",
    "To minimize the cost function, we take the derivative with respect to $ \\boldsymbol{\\beta} $ and set it to zero:\n",
    "$$ \\frac{\\partial J}{\\partial \\boldsymbol{\\beta}} = -\\frac{2}{n} \\mathbf{X}^T (\\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta}) = 0 $$\n",
    "\n",
    "Solving for $ \\boldsymbol{\\beta} $ gives:\n",
    "$$ \\boldsymbol{\\beta} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y} $$\n",
    "This equation is known as the **normal equation** and provides the least-squares estimates of the coefficients.\n",
    "\n",
    "#### Interpretation of the coefficients\n",
    "- **Intercept ($ \\beta_0 $)**: The expected value of $ y $ when all $ x $ variables are zero.\n",
    "- **Slope ($ \\beta_i $)**: The change in the expected value of $ y $ for a one-unit change in $ x_i $, holding all other variables constant.\n",
    "\n",
    "#### Evaluating model performance\n",
    "1. **Mean Squared Error (MSE)**: The average of the squares of the residuals, providing a measure of the model's accuracy.\n",
    "2. **R-squared ($ R^2 $)**: The proportion of the variance in the dependent variable that is predictable from the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q1: How do you install the necessary PyTorch libraries using a Jupyter notebook?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q2: How do you import the required libraries for linear regression?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q3: How do you check the version of PyTorch installed?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q4: How do you generate synthetic data for linear regression in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q5: How do you add noise to the synthetic data to simulate real-world scenarios?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q6: How do you visualize the synthetic data using `matplotlib`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q7: How do you split the synthetic data into training and testing sets?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q8: How do you define a simple linear regression model using `nn.Module` in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q9: How do you initialize the weights and biases of the linear regression model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q10: How do you print the model summary to view its structure?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q11: How do you define a loss function for linear regression in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q12: How do you choose and configure an optimizer for your linear regression model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q13: What is the purpose of the learning rate in the optimizer, and how do you set it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q14: How do you create a training loop for linear regression in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q15: How do you update the model parameters during training?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q16: How do you calculate and print the training loss during each epoch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q17: How do you visualize the training loss over epochs using matplotlib?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q18: How do you use early stopping to prevent overfitting during training?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q19: How do you make predictions using your trained linear regression model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q20: How do you evaluate the model's performance using metrics like Mean Squared Error (MSE)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q21: How do you visualize the model's predictions against the actual data using `matplotlib`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q22: How do you calculate the $R$-squared value to evaluate the goodness-of-fit for your model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q23: How do you save the trained linear regression model in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q24: How do you load a saved linear regression model in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q25: How do you save and load the model's state dictionary in PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q26: How do you perform hyperparameter tuning to improve the performance of your linear regression model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q27: How do you implement learning rate scheduling to adjust the learning rate during training?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q28: How do you normalize or standardize your data before training a linear regression model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q29: How do you handle multicollinearity in linear regression models?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q30: How do you implement polynomial regression using PyTorch to capture non-linear relationships?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q31: How do you extend the linear regression model to handle multiple features (multivariate linear regression)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q32: How do you use PyTorch to perform linear regression on a real-world dataset, such as the Boston Housing dataset?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q33: How do you implement ridge regression (L2 regularization) using PyTorch to prevent overfitting?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q34: How do you implement lasso regression (L1 regularization) using PyTorch to enforce sparsity in the model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Q35: How do you visualize the learned weights of the linear regression model to interpret feature importance?**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
